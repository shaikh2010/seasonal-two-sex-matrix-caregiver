{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1ErjzpjEH0my4KlZLAN6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaikh2010/seasonal-two-sex-matrix-caregiver/blob/main/Untitled39.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Polar bear (SBS; caregiver baseline; P=1) replication script\n",
        "# --------------------------------------------------------------\n",
        "# This Colab-ready script reproduces the polar-bear caregiver-baseline\n",
        "# results reported in the manuscript (see Section X.X / Appendix Y):\n",
        "#   1) Constructs the two-sex projection operator L (block lower-triangular)\n",
        "#   2) Computes lambda = rho(L) and R0 = rho( R (I - U_f)^{-1} )\n",
        "#   3) Recreates the manuscript figures:\n",
        "#        - pb_projection_balanced.png\n",
        "#        - pb_projection_log.png\n",
        "#        - pb_elasticities.png\n",
        "#   4) Writes machine-readable audit artifacts under ./out/\n",
        "#\n",
        "# Reproducibility contract:\n",
        "#   - Given the fixed primitives in PB (below), outputs are deterministic.\n",
        "#   - No external data are downloaded; no randomness is used.\n",
        "# Environment:\n",
        "#   - Tested in Google Colab (Python 3.x; numpy/pandas/matplotlib).\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "# -----------------------------\n",
        "# Paths / outputs\n",
        "# -----------------------------\n",
        "ROOT = Path(\".\")\n",
        "OUT = ROOT / \"out\"\n",
        "FIGS = OUT / \"figs\"\n",
        "PARAMS = OUT / \"params\"\n",
        "SUMMARY = OUT / \"summary\"\n",
        "TABLES = OUT / \"tables\"\n",
        "\n",
        "for d in [FIGS, PARAMS, SUMMARY, TABLES]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def spectral_radius(A: np.ndarray) -> float:\n",
        "    \"\"\"Spectral radius rho(A) = max |eig(A)|.\"\"\"\n",
        "    vals = la.eigvals(A)\n",
        "    return float(np.max(np.abs(vals)))\n",
        "\n",
        "\n",
        "def perron_left_right(A: np.ndarray):\n",
        "    \"\"\"\n",
        "    Perron (dominant) eigenvalue + left/right eigenvectors for a nonnegative primitive matrix.\n",
        "    Returns (lam, v, w) where:\n",
        "      A w = lam w,  v^T A = lam v^T\n",
        "      v^T w = 1\n",
        "    \"\"\"\n",
        "    vals, vecs = la.eig(A)\n",
        "    idx = int(np.argmax(np.abs(vals)))\n",
        "    lam = float(np.real(vals[idx]))\n",
        "\n",
        "    w = np.real(vecs[:, idx])\n",
        "\n",
        "    valsL, vecsL = la.eig(A.T)\n",
        "    idxL = int(np.argmax(np.abs(valsL)))\n",
        "    v = np.real(vecsL[:, idxL])\n",
        "\n",
        "    # Make them \"mostly\" positive (sign convention)\n",
        "    if np.sum(w) < 0:\n",
        "        w = -w\n",
        "    if np.sum(v) < 0:\n",
        "        v = -v\n",
        "\n",
        "    # Enforce strictly real and normalize v^T w = 1\n",
        "    denom = float(v @ w)\n",
        "    if abs(denom) < 1e-14:\n",
        "        raise RuntimeError(\"Normalization failed: v^T w ~ 0.\")\n",
        "    v = v / denom\n",
        "\n",
        "    return lam, v, w\n",
        "\n",
        "\n",
        "def check_column_sums_leq_one(U: np.ndarray, name: str, tol: float = 1e-12):\n",
        "    col_sums = U.sum(axis=0)\n",
        "    bad = np.where(col_sums > 1.0 + tol)[0]\n",
        "    if bad.size > 0:\n",
        "        raise ValueError(\n",
        "            f\"{name}: column sums exceed 1 (to-from convention). \"\n",
        "            f\"Bad columns (1-based): {list(bad + 1)}; sums={col_sums[bad]}\"\n",
        "        )\n",
        "\n",
        "\n",
        "def save_json(path: Path, obj):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Polar-bear primitives (Table pbparams; SBS; P=1)\n",
        "# -----------------------------\n",
        "PB = {\n",
        "    \"alpha\": 0.50,                 # female fraction among recruits\n",
        "    \"s_f1\": 0.62,                  # cub -> subadult survival\n",
        "    \"s_f2\": 0.88,                  # subadult -> solitary adult survival\n",
        "    \"s_adult_prim\": 0.93,          # solitary adult survival (primitive)\n",
        "    \"s_mother_COY_prim\": 0.93,     # COY-mother survival (primitive)\n",
        "    \"s_mother_YRL_prim\": 0.93,     # yearling-mother survival (primitive)\n",
        "    \"p_breed\": 0.45,               # breeding probability\n",
        "    \"s_COY\": 0.65,                 # dependent COY survival\n",
        "    \"s_YRL\": 0.80,                 # dependent yearling survival (reported; not used in mother-only bookkeeping)\n",
        "    \"litter_size\": 1.6,            # mean litter size\n",
        "    # male survival proxies (do not govern lambda in caregiver baseline if rho(M_f) > rho(M_m))\n",
        "    \"s_m1\": 0.90,\n",
        "    \"s_m2\": 0.90,\n",
        "    \"s_m3\": 0.96,\n",
        "}\n",
        "\n",
        "# Stage definitions (fixed for this model)\n",
        "female_stages = [\"F1 (cub)\", \"F2 (subadult)\", \"F3 (solitary adult)\", \"F4 (COY-mother)\", \"F5 (YRL-mother)\"]\n",
        "male_stages   = [\"M1 (juvenile)\", \"M2 (subadult)\", \"M3 (adult)\"]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Build matrices (caregiver baseline; P=1)\n",
        "# -----------------------------\n",
        "def build_polar_bear_blocks(prm: dict):\n",
        "    \"\"\"\n",
        "    Constructs:\n",
        "      U_f (5x5), U_m (3x3), fecundity vector f (5,), alpha\n",
        "    under the mother-only caregiver bookkeeping in the manuscript.\n",
        "    \"\"\"\n",
        "    alpha = float(prm[\"alpha\"])\n",
        "\n",
        "    s_f1 = float(prm[\"s_f1\"])\n",
        "    s_f2 = float(prm[\"s_f2\"])\n",
        "\n",
        "    s_adult = float(prm[\"s_adult_prim\"])\n",
        "    s_mCOY  = float(prm[\"s_mother_COY_prim\"])\n",
        "    s_mYRL  = float(prm[\"s_mother_YRL_prim\"])\n",
        "\n",
        "    p_breed = float(prm[\"p_breed\"])\n",
        "    s_COY   = float(prm[\"s_COY\"])\n",
        "    litter  = float(prm[\"litter_size\"])\n",
        "\n",
        "    # Derived annual fecundity (total recruits to next census, both sexes, per adult female per year)\n",
        "    b3 = p_breed * litter\n",
        "\n",
        "    # Composite caregiver-loop entries (to-from indexing: row=To, col=From)\n",
        "    u33 = s_adult * (1.0 - p_breed)      # F3 -> F3\n",
        "    u43 = s_adult * p_breed              # F3 -> F4\n",
        "    u54 = s_mCOY * s_COY                 # F4 -> F5\n",
        "    u34 = s_mCOY * (1.0 - s_COY)         # F4 -> F3\n",
        "    u35 = s_mYRL                         # F5 -> F3 (mother-only bookkeeping)\n",
        "\n",
        "    # Female survival/transition block U_f\n",
        "    U_f = np.zeros((5, 5), dtype=float)\n",
        "    U_f[1, 0] = s_f1     # F1 -> F2\n",
        "    U_f[2, 1] = s_f2     # F2 -> F3\n",
        "    U_f[2, 2] = u33      # F3 -> F3\n",
        "    U_f[3, 2] = u43      # F3 -> F4\n",
        "    U_f[4, 3] = u54      # F4 -> F5\n",
        "    U_f[2, 3] = u34      # F4 -> F3\n",
        "    U_f[2, 4] = u35      # F5 -> F3\n",
        "\n",
        "    # Male survival/transition block U_m (proxy)\n",
        "    U_m = np.zeros((3, 3), dtype=float)\n",
        "    U_m[1, 0] = float(prm[\"s_m1\"])  # M1 -> M2\n",
        "    U_m[2, 1] = float(prm[\"s_m2\"])  # M2 -> M3\n",
        "    U_m[2, 2] = float(prm[\"s_m3\"])  # M3 -> M3\n",
        "\n",
        "    # Fecundity vector f (total recruits to next census, both sexes, per female stage)\n",
        "    f = np.zeros(5, dtype=float)\n",
        "    f[2] = b3  # only solitary adult females reproduce in this baseline\n",
        "\n",
        "    # Validation: survival blocks should have column sums <= 1\n",
        "    check_column_sums_leq_one(U_f, \"U_f\")\n",
        "    check_column_sums_leq_one(U_m, \"U_m\")\n",
        "\n",
        "    # Also sanity-check probability ranges\n",
        "    if not (0.0 <= alpha <= 1.0):\n",
        "        raise ValueError(\"alpha must be in [0,1].\")\n",
        "    if np.any(U_f < -1e-15) or np.any(U_m < -1e-15):\n",
        "        raise ValueError(\"Matrices must be nonnegative.\")\n",
        "    if np.any(f < -1e-15):\n",
        "        raise ValueError(\"Fecundities must be nonnegative.\")\n",
        "\n",
        "    # Composite mapping table (audit)\n",
        "    mapping_rows = [\n",
        "        {\"to\": \"F2\", \"from\": \"F1\", \"symbol\": \"u^(f)_{2,1}\", \"expression\": \"s_f1\", \"value\": s_f1},\n",
        "        {\"to\": \"F3\", \"from\": \"F2\", \"symbol\": \"u^(f)_{3,2}\", \"expression\": \"s_f2\", \"value\": s_f2},\n",
        "        {\"to\": \"F3\", \"from\": \"F3\", \"symbol\": \"u^(f)_{3,3}\", \"expression\": \"s_adult*(1-p_breed)\", \"value\": u33},\n",
        "        {\"to\": \"F4\", \"from\": \"F3\", \"symbol\": \"u^(f)_{4,3}\", \"expression\": \"s_adult*p_breed\", \"value\": u43},\n",
        "        {\"to\": \"F5\", \"from\": \"F4\", \"symbol\": \"u^(f)_{5,4}\", \"expression\": \"s_mCOY*s_COY\", \"value\": u54},\n",
        "        {\"to\": \"F3\", \"from\": \"F4\", \"symbol\": \"u^(f)_{3,4}\", \"expression\": \"s_mCOY*(1-s_COY)\", \"value\": u34},\n",
        "        {\"to\": \"F3\", \"from\": \"F5\", \"symbol\": \"u^(f)_{3,5}\", \"expression\": \"s_mYRL\", \"value\": u35},\n",
        "        {\"to\": \"F1\", \"from\": \"F3\", \"symbol\": \"(A_f)_{1,3}\", \"expression\": \"alpha*b3 = alpha*(p_breed*litter)\", \"value\": alpha * b3},\n",
        "    ]\n",
        "\n",
        "    derived = {\n",
        "        \"b3_total_recruits_both_sexes\": b3,\n",
        "        \"u33\": u33, \"u43\": u43, \"u54\": u54, \"u34\": u34, \"u35\": u35\n",
        "    }\n",
        "\n",
        "    return U_f, U_m, f, alpha, mapping_rows, derived\n",
        "\n",
        "\n",
        "def build_caregiver_baseline_operator(U_f: np.ndarray, U_m: np.ndarray, f: np.ndarray, alpha: float):\n",
        "    \"\"\"\n",
        "    Builds:\n",
        "      R (female recruitment matrix, 5x5), A_f (5x5),\n",
        "      B (male recruit block, 3x5), L (8x8).\n",
        "    \"\"\"\n",
        "    nf = U_f.shape[0]\n",
        "    nm = U_m.shape[0]\n",
        "\n",
        "    e1f = np.zeros(nf, dtype=float); e1f[0] = 1.0\n",
        "    e1m = np.zeros(nm, dtype=float); e1m[0] = 1.0\n",
        "\n",
        "    R = alpha * np.outer(e1f, f)                  # 5x5\n",
        "    A_f = U_f + R                                  # 5x5\n",
        "    B = (1.0 - alpha) * np.outer(e1m, f)           # 3x5\n",
        "\n",
        "    L = np.zeros((nf + nm, nf + nm), dtype=float)\n",
        "    L[:nf, :nf] = A_f\n",
        "    L[nf:, :nf] = B\n",
        "    L[nf:, nf:] = U_m\n",
        "\n",
        "    return R, A_f, B, L\n",
        "\n",
        "\n",
        "def compute_R0(U_f: np.ndarray, R: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    For P=1: K = R (I - U_f)^(-1),  R0 = rho(K)\n",
        "    Uses a linear solve (no explicit inverse in user-facing logic).\n",
        "    \"\"\"\n",
        "    nf = U_f.shape[0]\n",
        "    I = np.eye(nf)\n",
        "    # Solve (I - U_f) X = I  => X = (I - U_f)^(-1)\n",
        "    X = la.solve(I - U_f, I)\n",
        "    K = R @ X\n",
        "    return spectral_radius(K), K\n",
        "\n",
        "\n",
        "def entrywise_elasticities(A: np.ndarray):\n",
        "    \"\"\"\n",
        "    Entrywise elasticities of rho(A) w.r.t. entries a_ij:\n",
        "      S_ij = v_i w_j\n",
        "      E_ij = (a_ij / rho(A)) * S_ij\n",
        "    \"\"\"\n",
        "    lam, v, w = perron_left_right(A)\n",
        "    S = np.outer(v, w)\n",
        "    E = (A / lam) * S\n",
        "    return lam, v, w, S, E\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Build and compute polar-bear results\n",
        "# -----------------------------\n",
        "U_f, U_m, f, alpha, composite_mapping_rows, derived = build_polar_bear_blocks(PB)\n",
        "R, A_f, B, L = build_caregiver_baseline_operator(U_f, U_m, f, alpha)\n",
        "\n",
        "lambda_full = spectral_radius(L)         # = max(rho(A_f), rho(U_m)) because L is block lower-triangular\n",
        "lambda_f = spectral_radius(A_f)\n",
        "rho_Um = spectral_radius(U_m)\n",
        "rho_Uf = spectral_radius(U_f)\n",
        "\n",
        "R0, K = compute_R0(U_f, R)\n",
        "\n",
        "print(\"=== Polar bear (SBS; P=1) caregiver baseline ===\")\n",
        "print(f\"rho(U_f)  = {rho_Uf:.6f}\")\n",
        "print(f\"rho(U_m)  = {rho_Um:.6f}\")\n",
        "print(f\"lambda    = {lambda_full:.6f}  (should equal rho(A_f) when rho(A_f) >= rho(U_m))\")\n",
        "print(f\"rho(A_f)  = {lambda_f:.6f}\")\n",
        "print(f\"R0        = {R0:.6f}\")\n",
        "print(\"\")\n",
        "print(\"Expected (from manuscript):\")\n",
        "print(\"  lambda ≈ 1.040848\")\n",
        "print(\"  R0     ≈ 1.678714\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Write LaTeX macros for the manuscript (optional but convenient)\n",
        "# -----------------------------\n",
        "def write_metrics_macros(path: Path, pb_lambda: float, pb_R0: float):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    lines = [\n",
        "        \"% Auto-generated by polar-bear replication code\",\n",
        "        f\"\\\\providecommand{{\\\\pbRzero}}{{{pb_R0:.6f}}}\",\n",
        "        f\"\\\\providecommand{{\\\\pbLambda}}{{{pb_lambda:.6f}}}\",\n",
        "        \"\",\n",
        "    ]\n",
        "    path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "# Write in repo root (so \\IfFileExists{metrics_macros.tex}{...} can find it),\n",
        "# and also in out/ for auditability.\n",
        "write_metrics_macros(ROOT / \"metrics_macros.tex\", lambda_full, R0)\n",
        "write_metrics_macros(OUT / \"metrics_macros.tex\", lambda_full, R0)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Save audit artifacts (optional but helpful)\n",
        "# -----------------------------\n",
        "# 1) primitives\n",
        "save_json(PARAMS / \"params_polarbear.json\", PB)\n",
        "\n",
        "# 2) expanded inputs (matrices + derived)\n",
        "save_json(\n",
        "    PARAMS / \"polar_bear_input_full.json\",\n",
        "    {\n",
        "        \"stages\": {\"female\": female_stages, \"male\": male_stages},\n",
        "        \"alpha\": alpha,\n",
        "        \"fecundity_vector_f_total_recruits_both_sexes\": f.tolist(),\n",
        "        \"derived\": derived,\n",
        "        \"U_f\": U_f.tolist(),\n",
        "        \"U_m\": U_m.tolist(),\n",
        "        \"R_female_recruitment_matrix\": R.tolist(),\n",
        "        \"A_f\": A_f.tolist(),\n",
        "        \"B_male_recruit_block\": B.tolist(),\n",
        "        \"L_full_two_sex_baseline\": L.tolist(),\n",
        "        \"metrics\": {\n",
        "            \"rho_Uf\": rho_Uf,\n",
        "            \"rho_Um\": rho_Um,\n",
        "            \"lambda\": lambda_full,\n",
        "            \"rho_Af\": lambda_f,\n",
        "            \"R0\": R0,\n",
        "        },\n",
        "    },\n",
        ")\n",
        "\n",
        "# 3) composite mapping table\n",
        "pd.DataFrame(composite_mapping_rows).to_csv(PARAMS / \"pb_composite_mapping.csv\", index=False)\n",
        "\n",
        "# 4) full nonzero entries table (U_f, U_m, and induced recruitment entries)\n",
        "def nonzero_entries_table():\n",
        "    rows = []\n",
        "    # U_f\n",
        "    for i in range(U_f.shape[0]):\n",
        "        for j in range(U_f.shape[1]):\n",
        "            if abs(U_f[i, j]) > 0:\n",
        "                rows.append({\n",
        "                    \"block\": \"U_f\",\n",
        "                    \"to_index\": i + 1, \"from_index\": j + 1,\n",
        "                    \"to_stage\": female_stages[i], \"from_stage\": female_stages[j],\n",
        "                    \"value\": float(U_f[i, j])\n",
        "                })\n",
        "    # U_m\n",
        "    for i in range(U_m.shape[0]):\n",
        "        for j in range(U_m.shape[1]):\n",
        "            if abs(U_m[i, j]) > 0:\n",
        "                rows.append({\n",
        "                    \"block\": \"U_m\",\n",
        "                    \"to_index\": i + 1, \"from_index\": j + 1,\n",
        "                    \"to_stage\": male_stages[i], \"from_stage\": male_stages[j],\n",
        "                    \"value\": float(U_m[i, j])\n",
        "                })\n",
        "    # Induced recruitment entries (A_f and B) from fecundity\n",
        "    for i in range(A_f.shape[0]):\n",
        "        for j in range(A_f.shape[1]):\n",
        "            if abs(R[i, j]) > 0:\n",
        "                rows.append({\n",
        "                    \"block\": \"A_f (recruitment part)\",\n",
        "                    \"to_index\": i + 1, \"from_index\": j + 1,\n",
        "                    \"to_stage\": female_stages[i], \"from_stage\": female_stages[j],\n",
        "                    \"value\": float(R[i, j])\n",
        "                })\n",
        "    for i in range(B.shape[0]):\n",
        "        for j in range(B.shape[1]):\n",
        "            if abs(B[i, j]) > 0:\n",
        "                rows.append({\n",
        "                    \"block\": \"B (male recruits)\",\n",
        "                    \"to_index\": i + 1, \"from_index\": j + 1,\n",
        "                    \"to_stage\": male_stages[i], \"from_stage\": female_stages[j],\n",
        "                    \"value\": float(B[i, j])\n",
        "                })\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df.sort_values([\"block\", \"from_index\", \"to_index\"]).reset_index(drop=True)\n",
        "\n",
        "nz_df = nonzero_entries_table()\n",
        "nz_df.to_csv(PARAMS / \"pb_U_complete_nonzero.csv\", index=False)\n",
        "\n",
        "# 5) summary JSON (machine-readable)\n",
        "save_json(\n",
        "    SUMMARY / \"RESULTS_SUMMARY_polar_bear.json\",\n",
        "    {\n",
        "        \"system\": \"polar_bear_SBS\",\n",
        "        \"period_P\": 1,\n",
        "        \"metrics\": {\n",
        "            \"R0\": R0,\n",
        "            \"lambda\": lambda_full,\n",
        "            \"rho_Uf\": rho_Uf,\n",
        "            \"rho_Um\": rho_Um,\n",
        "        },\n",
        "        \"primitives\": PB,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Projections (30 years) and figures\n",
        "# -----------------------------\n",
        "def project_constant(L: np.ndarray, x0: np.ndarray, T: int) -> np.ndarray:\n",
        "    \"\"\"Project x(t+1)=L x(t) for t=0..T-1 (P=1).\"\"\"\n",
        "    X = np.zeros((T + 1, L.shape[0]), dtype=float)\n",
        "    X[0, :] = x0\n",
        "    for t in range(T):\n",
        "        X[t + 1, :] = L @ X[t, :]\n",
        "    return X\n",
        "\n",
        "\n",
        "def perron_right_vector(A: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Dominant right eigenvector (real, mostly positive).\"\"\"\n",
        "    vals, vecs = la.eig(A)\n",
        "    idx = int(np.argmax(np.abs(vals)))\n",
        "    w = np.real(vecs[:, idx])\n",
        "    if np.sum(w) < 0:\n",
        "        w = -w\n",
        "    # ensure nonnegative (small numerical noise)\n",
        "    w = np.maximum(w, 0.0)\n",
        "    return w\n",
        "\n",
        "\n",
        "T_years = 30\n",
        "time = np.arange(T_years + 1)\n",
        "\n",
        "# Log-scale panel: initialize at Perron right eigenvector of L (scaled for visualization)\n",
        "wL = perron_right_vector(L)\n",
        "\n",
        "# Scale so total females at t=0 are 1000 (arbitrary units)\n",
        "female_total_target = 1000.0\n",
        "scale = female_total_target / max(wL[:5].sum(), 1e-15)\n",
        "x0_log = wL * scale\n",
        "\n",
        "# Linear \"balanced\" panel: rescale male totals at t=0 to match female totals (for visibility)\n",
        "x0_bal = x0_log.copy()\n",
        "female_total0 = x0_bal[:5].sum()\n",
        "male_total0 = x0_bal[5:].sum()\n",
        "if male_total0 > 0:\n",
        "    x0_bal[5:] *= (female_total0 / male_total0)\n",
        "\n",
        "X_log = project_constant(L, x0_log, T_years)\n",
        "X_bal = project_constant(L, x0_bal, T_years)\n",
        "\n",
        "# Figure 1: pb_projection_balanced.png (linear scale)\n",
        "plt.figure(figsize=(8, 4.8))\n",
        "for i in range(5):\n",
        "    plt.plot(time, X_bal[:, i], linestyle=\"-\", label=female_stages[i])\n",
        "for j in range(3):\n",
        "    plt.plot(time, X_bal[:, 5 + j], linestyle=\"--\", label=male_stages[j])\n",
        "\n",
        "plt.xlabel(\"Year (t)\")\n",
        "plt.ylabel(\"Abundance (arbitrary units)\")\n",
        "plt.title(\"Polar bear projections (caregiver baseline; balanced start; linear scale)\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(ncol=2, fontsize=9)\n",
        "plt.tight_layout()\n",
        "pb_balanced_path = FIGS / \"pb_projection_balanced.png\"\n",
        "plt.savefig(pb_balanced_path, dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# Figure 2: pb_projection_log.png (log scale)\n",
        "plt.figure(figsize=(8, 4.8))\n",
        "for i in range(5):\n",
        "    plt.plot(time, X_log[:, i], linestyle=\"-\", label=female_stages[i])\n",
        "for j in range(3):\n",
        "    plt.plot(time, X_log[:, 5 + j], linestyle=\"--\", label=male_stages[j])\n",
        "\n",
        "plt.xlabel(\"Year (t)\")\n",
        "plt.ylabel(\"Abundance (log scale)\")\n",
        "plt.yscale(\"log\")\n",
        "plt.title(\"Polar bear projections (caregiver baseline; Perron start; log scale)\")\n",
        "plt.grid(True, which=\"both\", alpha=0.3)\n",
        "plt.legend(ncol=2, fontsize=9)\n",
        "plt.tight_layout()\n",
        "pb_log_path = FIGS / \"pb_projection_log.png\"\n",
        "plt.savefig(pb_log_path, dpi=300)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Elasticities figure: pb_elasticities.png\n",
        "# -----------------------------\n",
        "lamA, vA, wA, SA, EA = entrywise_elasticities(A_f)\n",
        "\n",
        "# Collect nonzero entries of A_f for a clean bar plot\n",
        "rows = []\n",
        "for i in range(A_f.shape[0]):\n",
        "    for j in range(A_f.shape[1]):\n",
        "        if abs(A_f[i, j]) > 0:\n",
        "            rows.append({\n",
        "                \"to_index\": i + 1,\n",
        "                \"from_index\": j + 1,\n",
        "                \"to_stage\": female_stages[i],\n",
        "                \"from_stage\": female_stages[j],\n",
        "                \"A_entry\": float(A_f[i, j]),\n",
        "                \"elasticity\": float(EA[i, j]),\n",
        "                \"label\": f\"{female_stages[j].split(' ')[0]} → {female_stages[i].split(' ')[0]}\",\n",
        "                \"detail\": f\"{female_stages[j]} → {female_stages[i]}\",\n",
        "            })\n",
        "\n",
        "elas_df = pd.DataFrame(rows).sort_values(\"elasticity\", ascending=True).reset_index(drop=True)\n",
        "elas_df.to_csv(TABLES / \"pb_elasticities_entries.csv\", index=False)\n",
        "\n",
        "plt.figure(figsize=(9, 4.8))\n",
        "plt.barh(elas_df[\"detail\"], elas_df[\"elasticity\"])\n",
        "plt.xlabel(\"Elasticity of ρ(A_f) (sum over all entries = 1)\")\n",
        "plt.title(\"Polar bear: entrywise elasticities of female projection matrix A_f\")\n",
        "plt.grid(True, axis=\"x\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "pb_elas_path = FIGS / \"pb_elasticities.png\"\n",
        "plt.savefig(pb_elas_path, dpi=300)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Convenience: also copy figures to the notebook root (optional)\n",
        "# so LaTeX can find them via \\graphicspath{{./}{out/figs/}}\n",
        "# -----------------------------\n",
        "for fname in [\"pb_projection_balanced.png\", \"pb_projection_log.png\", \"pb_elasticities.png\"]:\n",
        "    src = FIGS / fname\n",
        "    if src.exists():\n",
        "        shutil.copy2(src, ROOT / fname)\n",
        "\n",
        "print(\"\\nFigures written to:\")\n",
        "print(f\"  {pb_balanced_path}\")\n",
        "print(f\"  {pb_log_path}\")\n",
        "print(f\"  {pb_elas_path}\")\n",
        "print(\"\\nAlso copied to current directory for convenience:\")\n",
        "print(\"  ./pb_projection_balanced.png\")\n",
        "print(\"  ./pb_projection_log.png\")\n",
        "print(\"  ./pb_elasticities.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Fnm7BTp0Qv-x",
        "outputId": "ac05b9ba-0594-43ea-c96a-bb490ac034b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Polar bear (SBS; P=1) caregiver baseline ===\n",
            "rho(U_f)  = 0.930000\n",
            "rho(U_m)  = 0.960000\n",
            "lambda    = 1.040848  (should equal rho(A_f) when rho(A_f) >= rho(U_m))\n",
            "rho(A_f)  = 1.040848\n",
            "R0        = 1.678714\n",
            "\n",
            "Expected (from manuscript):\n",
            "  lambda ≈ 1.040848\n",
            "  R0     ≈ 1.678714\n",
            "\n",
            "Figures written to:\n",
            "  out/figs/pb_projection_balanced.png\n",
            "  out/figs/pb_projection_log.png\n",
            "  out/figs/pb_elasticities.png\n",
            "\n",
            "Also copied to current directory for convenience:\n",
            "  ./pb_projection_balanced.png\n",
            "  ./pb_projection_log.png\n",
            "  ./pb_elasticities.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PURPOSE AND MANUSCRIPT LINKAGE\n",
        "#\n",
        "# This script implements the uncertainty / parametric bootstrap\n",
        "# procedure described in Section X.X of the manuscript.\n",
        "#\n",
        "# Specifically:\n",
        "#   - Beta-PERT sampling corresponds to Eq. (12) and Table S3\n",
        "#   - The caregiver-baseline SBS model (P=1) corresponds to\n",
        "#     Section 2.3 and Appendix B\n",
        "#   - Lambda and R0 computations correspond to Propositions 1–2\n",
        "#\n",
        "# The script is intended for reproducibility and auditability,\n",
        "# not for interactive model development.\n",
        "# ============================================================\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "\n",
        "def ensure_dir(p: Path) -> None:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def spectral_radius(A: np.ndarray) -> float:\n",
        "    \"\"\"Spectral radius rho(A) for a small dense matrix.\"\"\"\n",
        "    eigvals = np.linalg.eigvals(A)\n",
        "    return float(np.max(np.abs(eigvals)))\n",
        "\n",
        "def fmt(x: float, nd: int = 4) -> str:\n",
        "    \"\"\"Format a float for LaTeX tables.\"\"\"\n",
        "    return f\"{x:.{nd}f}\"\n",
        "\n",
        "def safe_float(x: Any) -> float:\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Cannot convert to float: {x!r}\") from e\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Beta-PERT sampler\n",
        "# ----------------------------\n",
        "\n",
        "def beta_pert_sample(\n",
        "    rng: np.random.Generator,\n",
        "    a: float,\n",
        "    m: float,\n",
        "    b: float,\n",
        "    shape_lambda: float = 4.0,\n",
        "    size: Optional[int] = None,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Draw from a bounded Beta-PERT distribution on [a, b] with mode m.\n",
        "\n",
        "    Standard PERT mapping:\n",
        "        alpha = 1 + λ * (m - a) / (b - a)\n",
        "        beta  = 1 + λ * (b - m) / (b - a)\n",
        "        X ~ Beta(alpha, beta), return a + X * (b - a)\n",
        "\n",
        "    Parameters must satisfy: a <= m <= b and b > a (unless degenerate).\n",
        "    \"\"\"\n",
        "    a = float(a); m = float(m); b = float(b); shape_lambda = float(shape_lambda)\n",
        "    if b < a:\n",
        "        raise ValueError(f\"PERT bounds invalid: min={a} > max={b}\")\n",
        "    if not (a <= m <= b):\n",
        "        raise ValueError(f\"PERT mode must be within [min,max]: min={a}, mode={m}, max={b}\")\n",
        "    if np.isclose(b, a):\n",
        "        # Degenerate\n",
        "        if size is None:\n",
        "            return np.array(m, dtype=float)\n",
        "        return np.full(size, m, dtype=float)\n",
        "\n",
        "    alpha = 1.0 + shape_lambda * (m - a) / (b - a)\n",
        "    beta  = 1.0 + shape_lambda * (b - m) / (b - a)\n",
        "\n",
        "    x = rng.beta(alpha, beta, size=size)\n",
        "    return a + x * (b - a)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Polar bear model builder (SBS; P=1)\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class PolarBearPrimitives:\n",
        "    # Sex ratio at recruitment\n",
        "    alpha: float\n",
        "\n",
        "    # Female primitives\n",
        "    s_f1: float                 # F1 (cub) -> F2 (subadult)\n",
        "    s_f2: float                 # F2 (subadult) -> F3 (solitary adult)\n",
        "    s_adult_prim: float         # adult survival (primitive)\n",
        "    s_mother_COY_prim: float    # COY-mother survival (primitive)\n",
        "    s_mother_YRL_prim: float    # YRL-mother survival (primitive)\n",
        "    p_breed: float              # breeding probability (solitary adult)\n",
        "    s_COY: float                # dependent COY survival\n",
        "    s_YRL: float                # dependent yearling survival (reported; not used in mother-only bookkeeping)\n",
        "    litter_size: float          # litter size (mean)\n",
        "\n",
        "    # Male primitives (proxy; baseline lambda governed by females)\n",
        "    s_m1: float                 # M1 -> M2\n",
        "    s_m2: float                 # M2 -> M3\n",
        "    s_m3: float                 # M3 -> M3 retention\n",
        "\n",
        "\n",
        "def build_polar_bear_blocks(pr: PolarBearPrimitives) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Build U_f, U_m, fecundity vector f (total recruits to next census, both sexes),\n",
        "    and baseline matrices A_f, R (female recruitment matrix), B (male recruit block), L.\n",
        "    \"\"\"\n",
        "    # Unpack\n",
        "    alpha = pr.alpha\n",
        "\n",
        "    # Derived fecundity (as in manuscript): b3 = p_breed * litter_size\n",
        "    b3_total_recruits = pr.p_breed * pr.litter_size\n",
        "\n",
        "    # Female stages: F1 cub, F2 subadult, F3 solitary adult, F4 COY-mother, F5 YRL-mother\n",
        "    nf = 5\n",
        "    U_f = np.zeros((nf, nf), dtype=float)\n",
        "\n",
        "    # Primitive survivals / early transitions\n",
        "    U_f[1, 0] = pr.s_f1  # F1 -> F2\n",
        "    U_f[2, 1] = pr.s_f2  # F2 -> F3\n",
        "\n",
        "    # Composite caregiver loop (mother-only bookkeeping; matches manuscript mapping)\n",
        "    u33 = pr.s_adult_prim * (1.0 - pr.p_breed)     # F3 -> F3\n",
        "    u43 = pr.s_adult_prim * pr.p_breed             # F3 -> F4\n",
        "    u54 = pr.s_mother_COY_prim * pr.s_COY          # F4 -> F5\n",
        "    u34 = pr.s_mother_COY_prim * (1.0 - pr.s_COY)  # F4 -> F3\n",
        "    u35 = pr.s_mother_YRL_prim                     # F5 -> F3 (independent of s_YRL under mother-only bookkeeping)\n",
        "\n",
        "    U_f[2, 2] = u33\n",
        "    U_f[3, 2] = u43\n",
        "    U_f[4, 3] = u54\n",
        "    U_f[2, 3] = u34\n",
        "    U_f[2, 4] = u35\n",
        "\n",
        "    # Male stages: M1 juvenile, M2 subadult, M3 adult\n",
        "    nm = 3\n",
        "    U_m = np.zeros((nm, nm), dtype=float)\n",
        "    U_m[1, 0] = pr.s_m1\n",
        "    U_m[2, 1] = pr.s_m2\n",
        "    U_m[2, 2] = pr.s_m3\n",
        "\n",
        "    # Fecundity vector f: total recruits (both sexes) to next census per female stage\n",
        "    f = np.zeros(nf, dtype=float)\n",
        "    f[2] = b3_total_recruits  # only solitary adults reproduce in this baseline\n",
        "\n",
        "    # Recruitment placement\n",
        "    e1f = np.zeros(nf, dtype=float); e1f[0] = 1.0\n",
        "    e1m = np.zeros(nm, dtype=float); e1m[0] = 1.0\n",
        "    R = alpha * np.outer(e1f, f)          # female recruits enter F1\n",
        "    B = (1.0 - alpha) * np.outer(e1m, f)  # male recruits enter M1\n",
        "\n",
        "    A_f = U_f + R\n",
        "\n",
        "    # Full baseline L (two-sex, block lower-triangular)\n",
        "    L = np.zeros((nf + nm, nf + nm), dtype=float)\n",
        "    L[:nf, :nf] = A_f\n",
        "    L[nf:, :nf] = B\n",
        "    L[nf:, nf:] = U_m\n",
        "\n",
        "    return {\n",
        "        \"U_f\": U_f,\n",
        "        \"U_m\": U_m,\n",
        "        \"f\": f,\n",
        "        \"R\": R,\n",
        "        \"B\": B,\n",
        "        \"A_f\": A_f,\n",
        "        \"L\": L,\n",
        "    }\n",
        "\n",
        "\n",
        "def compute_lambda_and_R0(blocks: Dict[str, np.ndarray]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute caregiver-baseline metrics for P=1:\n",
        "      - lambda = rho(L) (equals rho(A_f) when female block dominates)\n",
        "      - R0 = rho( K ), where K = R (I - U_f)^(-1)\n",
        "    \"\"\"\n",
        "    U_f = blocks[\"U_f\"]\n",
        "    U_m = blocks[\"U_m\"]\n",
        "    R   = blocks[\"R\"]\n",
        "    A_f = blocks[\"A_f\"]\n",
        "    L   = blocks[\"L\"]\n",
        "\n",
        "    rho_Uf = spectral_radius(U_f)\n",
        "    rho_Um = spectral_radius(U_m)\n",
        "    rho_Af = spectral_radius(A_f)\n",
        "\n",
        "    # Full two-sex baseline (block triangular): rho(L) = max(rho(A_f), rho(U_m))\n",
        "    lam = spectral_radius(L)\n",
        "\n",
        "    # Next-generation operator: K = R (I - U_f)^(-1)\n",
        "    I = np.eye(U_f.shape[0], dtype=float)\n",
        "    # Solve for K without explicitly forming the inverse:\n",
        "    # K = R @ (I - U_f)^(-1)  <=>  K^T solves (I - U_f)^T K^T = R^T\n",
        "    K = np.linalg.solve((I - U_f).T, R.T).T\n",
        "    R0 = spectral_radius(K)\n",
        "\n",
        "    return {\n",
        "        \"rho_Uf\": rho_Uf,\n",
        "        \"rho_Um\": rho_Um,\n",
        "        \"rho_Af\": rho_Af,\n",
        "        \"lambda\": lam,\n",
        "        \"R0\": R0,\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Uncertainty config I/O\n",
        "# ----------------------------\n",
        "\n",
        "def try_import_yaml():\n",
        "    try:\n",
        "        import yaml  # type: ignore\n",
        "        return yaml\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_uncertainty_config(path: Path) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load uncertainty config from YAML or JSON.\n",
        "    Expected schema:\n",
        "      {\n",
        "        \"B\": 5000,\n",
        "        \"seed\": 12345,\n",
        "        \"shape_lambda\": 4.0,\n",
        "        \"distributions\": {\n",
        "            \"s_f1\": {\"min\":..., \"mode\":..., \"max\":...},\n",
        "            ...\n",
        "        }\n",
        "      }\n",
        "    \"\"\"\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(str(path))\n",
        "\n",
        "    if path.suffix.lower() in [\".yaml\", \".yml\"]:\n",
        "        yaml = try_import_yaml()\n",
        "        if yaml is None:\n",
        "            raise RuntimeError(\"PyYAML not available; either install pyyaml or use JSON config.\")\n",
        "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            return yaml.safe_load(f)\n",
        "    elif path.suffix.lower() == \".json\":\n",
        "        with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported config format: {path.suffix}\")\n",
        "\n",
        "def save_uncertainty_config(config: Dict[str, Any], yaml_path: Path, json_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Save config as YAML (if PyYAML available) and always as JSON.\n",
        "    \"\"\"\n",
        "    ensure_dir(yaml_path.parent)\n",
        "    ensure_dir(json_path.parent)\n",
        "\n",
        "    # Always write JSON\n",
        "    with json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, sort_keys=True)\n",
        "\n",
        "    # Write YAML if available\n",
        "    yaml = try_import_yaml()\n",
        "    if yaml is not None:\n",
        "        with yaml_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            yaml.safe_dump(config, f, sort_keys=False)\n",
        "\n",
        "\n",
        "def default_uncertainty_config_template() -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Template PERT ranges. Replace min/mode/max with your exact values\n",
        "    if you want to reproduce your earlier table exactly.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"system\": \"polar_bear_SBS\",\n",
        "        \"period_P\": 1,\n",
        "        \"B\": 5000,\n",
        "        \"seed\": 12345,\n",
        "        \"shape_lambda\": 4.0,  # common PERT choice; set to your run's value\n",
        "        \"note\": \"Edit distributions min/mode/max to match your archived uncertainty_config_used.yaml.\",\n",
        "        \"distributions\": {\n",
        "            # Female primitives (probabilities)\n",
        "            \"s_f1\":              {\"min\": 0.45, \"mode\": 0.62, \"max\": 0.75},\n",
        "            \"s_f2\":              {\"min\": 0.75, \"mode\": 0.88, \"max\": 0.95},\n",
        "            \"s_adult_prim\":      {\"min\": 0.90, \"mode\": 0.93, \"max\": 0.97},\n",
        "            \"s_mother_COY_prim\": {\"min\": 0.90, \"mode\": 0.93, \"max\": 0.97},\n",
        "            \"s_mother_YRL_prim\": {\"min\": 0.90, \"mode\": 0.93, \"max\": 0.97},\n",
        "            \"p_breed\":           {\"min\": 0.25, \"mode\": 0.45, \"max\": 0.70},\n",
        "            \"s_COY\":             {\"min\": 0.40, \"mode\": 0.65, \"max\": 0.85},\n",
        "\n",
        "            # Reported but not used in U_f (mother-only bookkeeping); keep fixed if desired\n",
        "            # If you sampled it previously, include it here.\n",
        "            \"s_YRL\":             {\"min\": 0.60, \"mode\": 0.80, \"max\": 0.90},\n",
        "\n",
        "            # Litter size (positive; not necessarily bounded by 1)\n",
        "            \"litter_size\":       {\"min\": 1.20, \"mode\": 1.60, \"max\": 2.00},\n",
        "        },\n",
        "        # Fixed parameters (not sampled)\n",
        "        \"fixed\": {\n",
        "            \"alpha\": 0.5,\n",
        "            \"s_m1\": 0.90,\n",
        "            \"s_m2\": 0.90,\n",
        "            \"s_m3\": 0.96,\n",
        "        },\n",
        "        # Baseline modes (for audit)\n",
        "        \"baseline_modes\": {\n",
        "            \"alpha\": 0.5,\n",
        "            \"s_f1\": 0.62,\n",
        "            \"s_f2\": 0.88,\n",
        "            \"s_adult_prim\": 0.93,\n",
        "            \"s_mother_COY_prim\": 0.93,\n",
        "            \"s_mother_YRL_prim\": 0.93,\n",
        "            \"p_breed\": 0.45,\n",
        "            \"s_COY\": 0.65,\n",
        "            \"s_YRL\": 0.80,\n",
        "            \"litter_size\": 1.60,\n",
        "            \"s_m1\": 0.90,\n",
        "            \"s_m2\": 0.90,\n",
        "            \"s_m3\": 0.96,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Monte Carlo driver\n",
        "# ----------------------------\n",
        "\n",
        "def run_uncertainty(config: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Run Monte Carlo sampling and return:\n",
        "      - draws DataFrame (as dict for JSON)\n",
        "      - summary stats for lambda and R0\n",
        "      - additional diagnostics\n",
        "    \"\"\"\n",
        "    B = int(config.get(\"B\", 5000))\n",
        "    seed = int(config.get(\"seed\", 12345))\n",
        "    shape_lambda = float(config.get(\"shape_lambda\", 4.0))\n",
        "\n",
        "    dists: Dict[str, Dict[str, float]] = config[\"distributions\"]\n",
        "    fixed: Dict[str, float] = {k: safe_float(v) for k, v in config.get(\"fixed\", {}).items()}\n",
        "\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    rows = []\n",
        "    bad_subcritical_count = 0\n",
        "    mismatch_equivalence = 0\n",
        "\n",
        "    for draw_id in range(1, B + 1):\n",
        "        # Start with fixed values\n",
        "        prm = dict(fixed)\n",
        "\n",
        "        # Draw PERT samples\n",
        "        for name, spec in dists.items():\n",
        "            a = safe_float(spec[\"min\"])\n",
        "            m = safe_float(spec[\"mode\"])\n",
        "            b = safe_float(spec[\"max\"])\n",
        "            prm[name] = float(beta_pert_sample(rng, a, m, b, shape_lambda))\n",
        "\n",
        "        # Build primitives\n",
        "        pr = PolarBearPrimitives(\n",
        "            alpha=prm[\"alpha\"],\n",
        "            s_f1=prm[\"s_f1\"],\n",
        "            s_f2=prm[\"s_f2\"],\n",
        "            s_adult_prim=prm[\"s_adult_prim\"],\n",
        "            s_mother_COY_prim=prm[\"s_mother_COY_prim\"],\n",
        "            s_mother_YRL_prim=prm[\"s_mother_YRL_prim\"],\n",
        "            p_breed=prm[\"p_breed\"],\n",
        "            s_COY=prm[\"s_COY\"],\n",
        "            s_YRL=prm[\"s_YRL\"],\n",
        "            litter_size=prm[\"litter_size\"],\n",
        "            s_m1=prm[\"s_m1\"],\n",
        "            s_m2=prm[\"s_m2\"],\n",
        "            s_m3=prm[\"s_m3\"],\n",
        "        )\n",
        "\n",
        "        blocks = build_polar_bear_blocks(pr)\n",
        "        mets = compute_lambda_and_R0(blocks)\n",
        "\n",
        "        # Diagnostics: subcritical rho(U_f)<1 requirement for K validity (P=1)\n",
        "        if mets[\"rho_Uf\"] >= 1.0:\n",
        "            bad_subcritical_count += 1\n",
        "\n",
        "        # If you rely on threshold equivalence draw-by-draw, test it:\n",
        "        # (Under subcritical rho(U_f)<1, for P=1 caregiver baseline, R0>1 iff lambda>1.)\n",
        "        # In practice floating-point tolerances can cause rare mismatches near 1.\n",
        "        lam_gt = mets[\"lambda\"] > 1.0\n",
        "        r0_gt  = mets[\"R0\"] > 1.0\n",
        "        if lam_gt != r0_gt:\n",
        "            mismatch_equivalence += 1\n",
        "\n",
        "        # Record draw\n",
        "        row = {\n",
        "            \"draw_id\": draw_id,\n",
        "            # primitives drawn\n",
        "            \"alpha\": pr.alpha,\n",
        "            \"s_f1\": pr.s_f1,\n",
        "            \"s_f2\": pr.s_f2,\n",
        "            \"s_adult_prim\": pr.s_adult_prim,\n",
        "            \"s_mother_COY_prim\": pr.s_mother_COY_prim,\n",
        "            \"s_mother_YRL_prim\": pr.s_mother_YRL_prim,\n",
        "            \"p_breed\": pr.p_breed,\n",
        "            \"s_COY\": pr.s_COY,\n",
        "            \"s_YRL\": pr.s_YRL,  # reported / optional\n",
        "            \"litter_size\": pr.litter_size,\n",
        "            # male proxies\n",
        "            \"s_m1\": pr.s_m1,\n",
        "            \"s_m2\": pr.s_m2,\n",
        "            \"s_m3\": pr.s_m3,\n",
        "            # metrics\n",
        "            \"rho_Uf\": mets[\"rho_Uf\"],\n",
        "            \"rho_Um\": mets[\"rho_Um\"],\n",
        "            \"rho_Af\": mets[\"rho_Af\"],\n",
        "            \"lambda\": mets[\"lambda\"],\n",
        "            \"R0\": mets[\"R0\"],\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    def summarize(series: pd.Series) -> Dict[str, float]:\n",
        "        x = series.to_numpy(dtype=float)\n",
        "        return {\n",
        "            \"mean\": float(np.mean(x)),\n",
        "            \"sd\": float(np.std(x, ddof=1)),\n",
        "            \"q025\": float(np.quantile(x, 0.025)),\n",
        "            \"q50\": float(np.quantile(x, 0.50)),\n",
        "            \"q975\": float(np.quantile(x, 0.975)),\n",
        "            \"pr_gt_1\": float(np.mean(x > 1.0)),\n",
        "        }\n",
        "\n",
        "    summ_lambda = summarize(df[\"lambda\"])\n",
        "    summ_R0 = summarize(df[\"R0\"])\n",
        "\n",
        "    summary = {\n",
        "        \"system\": config.get(\"system\", \"polar_bear_SBS\"),\n",
        "        \"period_P\": int(config.get(\"period_P\", 1)),\n",
        "        \"B\": B,\n",
        "        \"seed\": seed,\n",
        "        \"shape_lambda\": shape_lambda,\n",
        "        \"summary\": {\n",
        "            \"lambda\": summ_lambda,\n",
        "            \"R0\": summ_R0,\n",
        "        },\n",
        "        \"diagnostics\": {\n",
        "            \"count_rho_Uf_ge_1\": int(bad_subcritical_count),\n",
        "            \"count_threshold_mismatch\": int(mismatch_equivalence),\n",
        "        },\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        \"draws_df\": df,\n",
        "        \"summary\": summary,\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# LaTeX writers (table + macros)\n",
        "# ----------------------------\n",
        "\n",
        "def write_latex_uncertainty_table(summary: Dict[str, Any], out_tex_path: Path, nd: int = 4) -> None:\n",
        "    \"\"\"\n",
        "    Write a LaTeX tabular body matching your manuscript \\input usage:\n",
        "      out_full_with_uncertaintypolarbear/tables/pb_uncertainty_metrics.tex\n",
        "    \"\"\"\n",
        "    ensure_dir(out_tex_path.parent)\n",
        "\n",
        "    sL = summary[\"summary\"][\"lambda\"]\n",
        "    sR = summary[\"summary\"][\"R0\"]\n",
        "\n",
        "    lines = []\n",
        "    lines.append(r\"\\begin{tabular}{@{}lrrrrr r@{}}\")\n",
        "    lines.append(r\"\\toprule\")\n",
        "    lines.append(r\"Metric & Mean & SD & 2.5\\% & 50\\% & 97.5\\% & $\\Pr(>1)$\\\\\")\n",
        "    lines.append(r\"\\midrule\")\n",
        "    lines.append(\n",
        "        rf\"$\\lambda$ & {fmt(sL['mean'], nd)} & {fmt(sL['sd'], nd)} & {fmt(sL['q025'], nd)} & {fmt(sL['q50'], nd)} & {fmt(sL['q975'], nd)} & {fmt(sL['pr_gt_1'], nd)}\\\\\"\n",
        "    )\n",
        "    lines.append(\n",
        "        rf\"$R_0$ & {fmt(sR['mean'], nd)} & {fmt(sR['sd'], nd)} & {fmt(sR['q025'], nd)} & {fmt(sR['q50'], nd)} & {fmt(sR['q975'], nd)} & {fmt(sR['pr_gt_1'], nd)}\\\\\"\n",
        "    )\n",
        "    lines.append(r\"\\bottomrule\")\n",
        "    lines.append(r\"\\end{tabular}\")\n",
        "    lines.append(\"\")  # trailing newline\n",
        "\n",
        "    out_tex_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def write_uncertainty_macros(summary: Dict[str, Any], out_macro_path: Path, nd: int = 6) -> None:\n",
        "    \"\"\"\n",
        "    Write LaTeX macros compatible with your \\PBset/\\PBuse wrapper and your manuscript defs:\n",
        "      \\PBset{pbLambdaP025}{...}, etc.\n",
        "    \"\"\"\n",
        "    ensure_dir(out_macro_path.parent)\n",
        "\n",
        "    sL = summary[\"summary\"][\"lambda\"]\n",
        "    sR = summary[\"summary\"][\"R0\"]\n",
        "\n",
        "    # NOTE: You can add additional macros here if you want mean/sd in TeX.\n",
        "    # Your manuscript already expects:\n",
        "    #   pbLambdaP025, pbLambdaP50, pbLambdaP975,\n",
        "    #   pbRzeroP025, pbRzeroP50, pbRzeroP975,\n",
        "    #   pbPrLambdaGTone, pbPrRzeroGTone\n",
        "    lines = []\n",
        "    lines.append(\"% Auto-generated by polar bear uncertainty script\")\n",
        "    lines.append(\"% Do not edit by hand; edit the Python config and regenerate.\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "    lines.append(rf\"\\PBset{{pbLambdaP025}}{{{fmt(sL['q025'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbLambdaP50}}{{{fmt(sL['q50'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbLambdaP975}}{{{fmt(sL['q975'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbPrLambdaGTone}}{{{fmt(sL['pr_gt_1'], nd)}}}\")\n",
        "\n",
        "    lines.append(rf\"\\PBset{{pbRzeroP025}}{{{fmt(sR['q025'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbRzeroP50}}{{{fmt(sR['q50'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbRzeroP975}}{{{fmt(sR['q975'], nd)}}}\")\n",
        "    lines.append(rf\"\\PBset{{pbPrRzeroGTone}}{{{fmt(sR['pr_gt_1'], nd)}}}\")\n",
        "\n",
        "    lines.append(\"\")  # trailing newline\n",
        "    out_macro_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Main (Colab-friendly)\n",
        "# ----------------------------\n",
        "\n",
        "def main() -> None:\n",
        "    # ---- Output roots (match your manuscript paths) ----\n",
        "    out_root = Path(\"out\")\n",
        "    out_unc = out_root / \"uncertainty\"\n",
        "    out_params = out_root / \"params\"\n",
        "\n",
        "    out_full = Path(\"out_full_with_uncertaintypolarbear\")\n",
        "    out_tables = out_full / \"tables\"\n",
        "    out_tex = out_full / \"tex\"\n",
        "    out_summary = out_full / \"summary\"\n",
        "\n",
        "    ensure_dir(out_unc)\n",
        "    ensure_dir(out_params)\n",
        "    ensure_dir(out_tables)\n",
        "    ensure_dir(out_tex)\n",
        "    ensure_dir(out_summary)\n",
        "\n",
        "    # ---- Load config if you have it; otherwise use template ----\n",
        "    # If you already have your archived config file, put it at one of these paths:\n",
        "    #   out/params/uncertainty_config_used.yaml\n",
        "    #   out/params/uncertainty_config_used.json\n",
        "    #   uncertainty_config_used.yaml\n",
        "    #   uncertainty_config_used.json\n",
        "    candidate_paths = [\n",
        "        out_params / \"uncertainty_config_used.yaml\",\n",
        "        out_params / \"uncertainty_config_used.json\",\n",
        "        Path(\"uncertainty_config_used.yaml\"),\n",
        "        Path(\"uncertainty_config_used.json\"),\n",
        "    ]\n",
        "\n",
        "    config = None\n",
        "    for p in candidate_paths:\n",
        "        if p.exists():\n",
        "            config = load_uncertainty_config(p)\n",
        "            break\n",
        "\n",
        "    if config is None:\n",
        "        config = default_uncertainty_config_template()\n",
        "\n",
        "    # ---- Run uncertainty ----\n",
        "    result = run_uncertainty(config)\n",
        "    df_draws: pd.DataFrame = result[\"draws_df\"]\n",
        "    summary: Dict[str, Any] = result[\"summary\"]\n",
        "\n",
        "    # ---- Save draw-level outputs ----\n",
        "    draws_csv_path = out_unc / \"pb_draws.csv\"\n",
        "    df_draws.to_csv(draws_csv_path, index=False)\n",
        "\n",
        "    # ---- Save summary JSON ----\n",
        "    summary_json_path = out_summary / \"UNCERTAINTY_SUMMARY_polar_bear.json\"\n",
        "    with summary_json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(summary, f, indent=2, sort_keys=True)\n",
        "\n",
        "    # ---- Save config used (YAML if possible; always JSON) ----\n",
        "    config_used_yaml = out_params / \"uncertainty_config_used.yaml\"\n",
        "    config_used_json = out_params / \"uncertainty_config_used.json\"\n",
        "    save_uncertainty_config(config, config_used_yaml, config_used_json)\n",
        "\n",
        "    # ---- Write LaTeX table and macros expected by your manuscript ----\n",
        "    table_tex_path = out_tables / \"pb_uncertainty_metrics.tex\"\n",
        "    macros_tex_path = out_tex / \"uncertainty_macros_polar_bear.tex\"\n",
        "\n",
        "    write_latex_uncertainty_table(summary, table_tex_path, nd=4)\n",
        "    write_uncertainty_macros(summary, macros_tex_path, nd=6)\n",
        "\n",
        "    # ---- Print a compact console summary (optional) ----\n",
        "    sL = summary[\"summary\"][\"lambda\"]\n",
        "    sR = summary[\"summary\"][\"R0\"]\n",
        "    print(\"=== Polar bear uncertainty (caregiver baseline; P=1) ===\")\n",
        "    print(f\"B={summary['B']}  seed={summary['seed']}  shape_lambda={summary['shape_lambda']}\")\n",
        "    print(\"\")\n",
        "    print(\"lambda summary:\")\n",
        "    print(f\"  mean={sL['mean']:.6f}, sd={sL['sd']:.6f}, q025={sL['q025']:.6f}, q50={sL['q50']:.6f}, q975={sL['q975']:.6f}, Pr(>1)={sL['pr_gt_1']:.6f}\")\n",
        "    print(\"R0 summary:\")\n",
        "    print(f\"  mean={sR['mean']:.6f}, sd={sR['sd']:.6f}, q025={sR['q025']:.6f}, q50={sR['q50']:.6f}, q975={sR['q975']:.6f}, Pr(>1)={sR['pr_gt_1']:.6f}\")\n",
        "    print(\"\")\n",
        "    print(\"Diagnostics:\")\n",
        "    print(f\"  count rho(U_f) >= 1: {summary['diagnostics']['count_rho_Uf_ge_1']}\")\n",
        "    print(f\"  count threshold mismatches (lambda>1 vs R0>1): {summary['diagnostics']['count_threshold_mismatch']}\")\n",
        "    print(\"\")\n",
        "    print(\"Wrote:\")\n",
        "    print(f\"  {draws_csv_path}\")\n",
        "    print(f\"  {table_tex_path}\")\n",
        "    print(f\"  {macros_tex_path}\")\n",
        "    print(f\"  {summary_json_path}\")\n",
        "    print(f\"  {config_used_yaml}  (if PyYAML available)\")\n",
        "    print(f\"  {config_used_json}\")\n",
        "\n",
        "\n",
        "# Run in notebook / Colab\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cEBSJp_5a17L",
        "outputId": "65e94f99-449c-4a39-948c-7ec251a1de36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:476: SyntaxWarning: invalid escape sequence '\\i'\n",
            "<>:504: SyntaxWarning: invalid escape sequence '\\P'\n",
            "<>:476: SyntaxWarning: invalid escape sequence '\\i'\n",
            "<>:504: SyntaxWarning: invalid escape sequence '\\P'\n",
            "/tmp/ipython-input-2964927003.py:476: SyntaxWarning: invalid escape sequence '\\i'\n",
            "  Write a LaTeX tabular body matching your manuscript \\input usage:\n",
            "/tmp/ipython-input-2964927003.py:504: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  Write LaTeX macros compatible with your \\PBset/\\PBuse wrapper and your manuscript defs:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Polar bear uncertainty (caregiver baseline; P=1) ===\n",
            "B=5000  seed=12345  shape_lambda=4.0\n",
            "\n",
            "lambda summary:\n",
            "  mean=1.040094, sd=0.018490, q025=1.006436, q50=1.039642, q975=1.077403, Pr(>1)=0.990600\n",
            "R0 summary:\n",
            "  mean=1.711993, sd=0.379889, q025=1.095210, q50=1.673300, q975=2.539195, Pr(>1)=0.990600\n",
            "\n",
            "Diagnostics:\n",
            "  count rho(U_f) >= 1: 0\n",
            "  count threshold mismatches (lambda>1 vs R0>1): 0\n",
            "\n",
            "Wrote:\n",
            "  out/uncertainty/pb_draws.csv\n",
            "  out_full_with_uncertaintypolarbear/tables/pb_uncertainty_metrics.tex\n",
            "  out_full_with_uncertaintypolarbear/tex/uncertainty_macros_polar_bear.tex\n",
            "  out_full_with_uncertaintypolarbear/summary/UNCERTAINTY_SUMMARY_polar_bear.json\n",
            "  out/params/uncertainty_config_used.yaml  (if PyYAML available)\n",
            "  out/params/uncertainty_config_used.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Prairie dog (USGS; P=12) replication script (Google Colab-ready)\n",
        "# Caregiver (female-driven) baseline + seasonal (periodic) R0_per\n",
        "#\n",
        "# Manuscript linkage:\n",
        "#   - Data ingestion and pooling rule: Methods Section X.X\n",
        "#   - Monthly caregiver-baseline model (newborns not a state): Section X.X / Appendix Y\n",
        "#   - Neutrality calibration (rho(M)=lambda^12=1): Section X.X\n",
        "#   - Periodic next-generation operator K and R0_per: Appendix Z\n",
        "#\n",
        "# Workflow implemented:\n",
        "#   - Ingest USGS survival + reproduction CSVs (Control/NONE treatment)\n",
        "#   - If survival CSV has no month field: pooled survival -> per-month via s_month = s_pooled^(1/m)\n",
        "#   - Build monthly two-sex caregiver-baseline matrices (newborns not a state)\n",
        "#   - Calibrate breeding-window fecundity scale s so that rho(M)=1 (annual neutrality)\n",
        "#   - Compute periodic next-generation operator K and R0_per = rho(K)\n",
        "#   - Produce figures under out/figs and audit artifacts under out/\n",
        "#\n",
        "# Inputs expected (upload to Colab runtime):\n",
        "#   - Survival CSV: columns {TREATMENT, AGE, SURVIVE} with AGE in {J,A}; MONTH optional\n",
        "#   - Reproduction CSV: columns {TREATMENT, JUVENILES, ADULTS}\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# Optional YAML support\n",
        "# ----------------------------\n",
        "\n",
        "def _try_import_yaml():\n",
        "    try:\n",
        "        import yaml  # type: ignore\n",
        "        return yaml\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "\n",
        "def ensure_dir(p: Path) -> None:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def spectral_radius(A: np.ndarray) -> float:\n",
        "    eigvals = np.linalg.eigvals(A)\n",
        "    return float(np.max(np.abs(eigvals)))\n",
        "\n",
        "def perron_right(A: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Return a nonnegative (approximately) Perron right eigenvector for a nonnegative matrix.\"\"\"\n",
        "    vals, vecs = np.linalg.eig(A)\n",
        "    idx = int(np.argmax(np.abs(vals)))\n",
        "    v = np.real(vecs[:, idx])\n",
        "    v = np.abs(v)\n",
        "    if np.allclose(v, 0):\n",
        "        v = np.ones(A.shape[0], dtype=float)\n",
        "    return v\n",
        "\n",
        "def induced_matrix_1norm(A: np.ndarray) -> float:\n",
        "    \"\"\"Induced matrix 1-norm (max column sum), matching the paper's ||T_k||_1 usage.\"\"\"\n",
        "    return float(np.linalg.norm(A, 1))\n",
        "\n",
        "def moving_average(x: np.ndarray, window: int = 3) -> np.ndarray:\n",
        "    if window <= 1:\n",
        "        return x.copy()\n",
        "    w = np.ones(window, dtype=float) / window\n",
        "    return np.convolve(x, w, mode=\"same\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Auto-detect input CSVs\n",
        "# ----------------------------\n",
        "\n",
        "def _lower_set(cols: List[str]) -> set:\n",
        "    return {c.strip().lower() for c in cols}\n",
        "\n",
        "def detect_survival_vs_reproduction_csv(csv_paths: List[Path]) -> Tuple[Path, Path]:\n",
        "    \"\"\"\n",
        "    Heuristic:\n",
        "      - survival CSV contains {age, survive} columns\n",
        "      - reproduction CSV contains {juveniles, adults} columns\n",
        "    \"\"\"\n",
        "    survival_candidates = []\n",
        "    repro_candidates = []\n",
        "\n",
        "    for p in csv_paths:\n",
        "        try:\n",
        "            df = pd.read_csv(p, nrows=5)\n",
        "        except Exception:\n",
        "            continue\n",
        "        cols = _lower_set(list(df.columns))\n",
        "\n",
        "        has_age = any(\"age\" == c or \"age_\" in c or c.endswith(\"age\") for c in cols)\n",
        "        has_survive = any(\"survive\" in c or \"survival\" in c for c in cols)\n",
        "\n",
        "        has_juv = any(\"juvenile\" in c or \"juv\" in c for c in cols)\n",
        "        has_adult = any(\"adult\" in c for c in cols)\n",
        "\n",
        "        if has_age and has_survive:\n",
        "            survival_candidates.append(p)\n",
        "        if has_juv and has_adult:\n",
        "            repro_candidates.append(p)\n",
        "\n",
        "    if len(survival_candidates) != 1 or len(repro_candidates) != 1:\n",
        "        msg = [\n",
        "            \"Could not uniquely identify survival and reproduction CSVs.\",\n",
        "            f\"Found CSVs: {[str(p) for p in csv_paths]}\",\n",
        "            f\"Survival candidates: {[str(p) for p in survival_candidates]}\",\n",
        "            f\"Reproduction candidates: {[str(p) for p in repro_candidates]}\",\n",
        "            \"\",\n",
        "            \"Fix by setting CONFIG.survival_csv and CONFIG.reproduction_csv explicitly.\",\n",
        "        ]\n",
        "        raise RuntimeError(\"\\n\".join(msg))\n",
        "\n",
        "    return survival_candidates[0], repro_candidates[0]\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "\n",
        "@dataclass\n",
        "class PrairieDogConfig:\n",
        "    # If None, auto-detect from *.csv in current working directory.\n",
        "    survival_csv: Optional[str] = None\n",
        "    reproduction_csv: Optional[str] = None\n",
        "\n",
        "    # Treatment label used as Control baseline in the paper\n",
        "    treatment_label: str = \"NONE\"\n",
        "\n",
        "    # Breeding months (Apr-Jun) as month indices 1..12\n",
        "    breeding_months: Tuple[int, ...] = (4, 5, 6)\n",
        "\n",
        "    # If survival CSV has no month field: interpret SURVIVE as interval survival over m months\n",
        "    interval_months_when_month_missing: int = 12\n",
        "\n",
        "    # Sex ratio at recruitment\n",
        "    alpha: float = 0.5\n",
        "\n",
        "    # Yearling fecundity fraction: b2,k = theta * b3,k in breeding months (default 0)\n",
        "    theta_yearling_fraction: float = 0.0\n",
        "\n",
        "    # Projection horizon\n",
        "    projection_months: int = 30\n",
        "\n",
        "    # Invasion curve settings (Beverton–Holt male availability)\n",
        "    invasion_hm: float = 1.0\n",
        "    invasion_eta_max: float = 10.0\n",
        "    invasion_eta_n: int = 250\n",
        "\n",
        "    # Numerical tolerance for neutrality calibration\n",
        "    bisect_iters: int = 80\n",
        "    bisect_tol: float = 1e-12\n",
        "\n",
        "\n",
        "CONFIG = PrairieDogConfig()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Ingestion: survival CSV\n",
        "# ----------------------------\n",
        "\n",
        "def find_column(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
        "    cols = list(df.columns)\n",
        "    lower = {c.lower(): c for c in cols}\n",
        "    for cand in candidates:\n",
        "        for k, orig in lower.items():\n",
        "            if cand in k:\n",
        "                return orig\n",
        "    return None\n",
        "\n",
        "def ingest_survival(\n",
        "    path: Path,\n",
        "    treatment_label: str,\n",
        "    interval_m: int = 12,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Implements the paper's rule:\n",
        "      - If month field exists: compute monthwise mean SURVIVE by AGE class.\n",
        "      - If month missing: pooled survival by AGE class, then convert to per-month via s_month = s_pooled^(1/m),\n",
        "        and replicate across months.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Detect columns\n",
        "    col_treat = find_column(df, [\"treat\"])\n",
        "    col_age = find_column(df, [\"age\"])\n",
        "    col_surv = find_column(df, [\"survive\", \"survival\"])\n",
        "\n",
        "    # Optional month field\n",
        "    col_month = find_column(df, [\"month\"])\n",
        "\n",
        "    if col_treat is None or col_age is None or col_surv is None:\n",
        "        raise RuntimeError(\n",
        "            \"Survival CSV missing required columns. \"\n",
        "            f\"Detected treat={col_treat}, age={col_age}, survive={col_surv}. \"\n",
        "            f\"Columns={list(df.columns)}\"\n",
        "        )\n",
        "\n",
        "    # Filter to treatment\n",
        "    tr = df[col_treat].astype(str).str.upper().str.strip()\n",
        "    df = df.loc[tr.eq(str(treatment_label).upper().strip())].copy()\n",
        "\n",
        "    # Standardize AGE\n",
        "    df[col_age] = df[col_age].astype(str).str.upper().str.strip()\n",
        "    # Standardize survive to numeric 0/1\n",
        "    df[col_surv] = pd.to_numeric(df[col_surv], errors=\"coerce\")\n",
        "\n",
        "    # Valid ages: J (juvenile) and A (adult), per your paper extract\n",
        "    df = df.loc[df[col_age].isin([\"J\", \"A\"])].copy()\n",
        "\n",
        "    if df.empty:\n",
        "        raise RuntimeError(f\"No rows left after filtering treatment={treatment_label} and AGE in {{J,A}}.\")\n",
        "\n",
        "    out = {\n",
        "        \"source_path\": str(path),\n",
        "        \"treatment_label\": str(treatment_label),\n",
        "        \"detected_columns\": {\n",
        "            \"treatment\": col_treat,\n",
        "            \"age\": col_age,\n",
        "            \"survive\": col_surv,\n",
        "            \"month\": col_month,\n",
        "        },\n",
        "        \"month_field_present\": col_month is not None,\n",
        "        \"interval_m_used_if_pooled\": int(interval_m),\n",
        "    }\n",
        "\n",
        "    if col_month is not None:\n",
        "        # Monthwise aggregation (expects month index 1..12)\n",
        "        df[col_month] = pd.to_numeric(df[col_month], errors=\"coerce\")\n",
        "        df = df.loc[df[col_month].between(1, 12, inclusive=\"both\")].copy()\n",
        "\n",
        "        g = df.groupby([col_month, col_age])[col_surv].agg([\"mean\", \"count\"]).reset_index()\n",
        "        # Initialize arrays\n",
        "        sJ = np.full(12, np.nan, dtype=float)\n",
        "        sA = np.full(12, np.nan, dtype=float)\n",
        "        nJ = np.zeros(12, dtype=int)\n",
        "        nA = np.zeros(12, dtype=int)\n",
        "\n",
        "        for _, r in g.iterrows():\n",
        "            m = int(r[col_month])  # 1..12\n",
        "            age = str(r[col_age])\n",
        "            if age == \"J\":\n",
        "                sJ[m-1] = float(r[\"mean\"])\n",
        "                nJ[m-1] = int(r[\"count\"])\n",
        "            elif age == \"A\":\n",
        "                sA[m-1] = float(r[\"mean\"])\n",
        "                nA[m-1] = int(r[\"count\"])\n",
        "\n",
        "        # Basic validation\n",
        "        if np.any(np.isnan(sJ)) or np.any(np.isnan(sA)):\n",
        "            raise RuntimeError(\"Month field present but some months missing AGE=J or AGE=A survival estimates.\")\n",
        "        out.update({\n",
        "            \"sJ_month\": sJ.tolist(),\n",
        "            \"sA_month\": sA.tolist(),\n",
        "            \"nJ_month\": nJ.tolist(),\n",
        "            \"nA_month\": nA.tolist(),\n",
        "            \"pooled\": None,\n",
        "        })\n",
        "        return out\n",
        "\n",
        "    # Pooled survival -> per-month conversion s_month = s_pooled^(1/m)\n",
        "    pooled = df.groupby(col_age)[col_surv].agg([\"mean\", \"count\"]).reset_index()\n",
        "    pooled_dict = {}\n",
        "    for _, r in pooled.iterrows():\n",
        "        pooled_dict[str(r[col_age])] = {\"mean\": float(r[\"mean\"]), \"count\": int(r[\"count\"])}\n",
        "\n",
        "    if \"J\" not in pooled_dict or \"A\" not in pooled_dict:\n",
        "        raise RuntimeError(\"Expected pooled survival for AGE=J and AGE=A.\")\n",
        "\n",
        "    sJ_pooled = pooled_dict[\"J\"][\"mean\"]\n",
        "    sA_pooled = pooled_dict[\"A\"][\"mean\"]\n",
        "    nJ = pooled_dict[\"J\"][\"count\"]\n",
        "    nA = pooled_dict[\"A\"][\"count\"]\n",
        "\n",
        "    # Conversion rule used in your manuscript:\n",
        "    sJ_month = float(sJ_pooled ** (1.0 / interval_m))\n",
        "    sA_month = float(sA_pooled ** (1.0 / interval_m))\n",
        "\n",
        "    sJ = np.full(12, sJ_month, dtype=float)\n",
        "    sA = np.full(12, sA_month, dtype=float)\n",
        "\n",
        "    out.update({\n",
        "        \"sJ_month\": sJ.tolist(),\n",
        "        \"sA_month\": sA.tolist(),\n",
        "        \"nJ_month\": [nJ]*12,\n",
        "        \"nA_month\": [nA]*12,\n",
        "        \"pooled\": {\n",
        "            \"sJ_pooled\": float(sJ_pooled),\n",
        "            \"sA_pooled\": float(sA_pooled),\n",
        "            \"nJ\": int(nJ),\n",
        "            \"nA\": int(nA),\n",
        "            \"sJ_month_converted\": float(sJ_month),\n",
        "            \"sA_month_converted\": float(sA_month),\n",
        "        }\n",
        "    })\n",
        "    return out\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Ingestion: reproduction CSV\n",
        "# ----------------------------\n",
        "\n",
        "def ingest_reproduction(\n",
        "    path: Path,\n",
        "    treatment_label: str,\n",
        "    breeding_months: Tuple[int, ...],\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Implements the paper's rule:\n",
        "      - Aggregate (sum) JUVENILES and ADULTS across all rows for treatment.\n",
        "      - ratio = JUVENILES_tot / ADULTS_tot\n",
        "      - base monthly adult fecundity in Apr-Jun: b3_base = ratio / 3\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    col_treat = find_column(df, [\"treat\"])\n",
        "    col_juv = find_column(df, [\"juvenile\", \"juv\"])\n",
        "    col_ad = find_column(df, [\"adult\"])\n",
        "\n",
        "    if col_treat is None or col_juv is None or col_ad is None:\n",
        "        raise RuntimeError(\n",
        "            \"Reproduction CSV missing required columns. \"\n",
        "            f\"Detected treat={col_treat}, juveniles={col_juv}, adults={col_ad}. \"\n",
        "            f\"Columns={list(df.columns)}\"\n",
        "        )\n",
        "\n",
        "    tr = df[col_treat].astype(str).str.upper().str.strip()\n",
        "    df = df.loc[tr.eq(str(treatment_label).upper().strip())].copy()\n",
        "    if df.empty:\n",
        "        raise RuntimeError(f\"No reproduction rows left after filtering treatment={treatment_label}.\")\n",
        "\n",
        "    df[col_juv] = pd.to_numeric(df[col_juv], errors=\"coerce\")\n",
        "    df[col_ad] = pd.to_numeric(df[col_ad], errors=\"coerce\")\n",
        "\n",
        "    juv_tot = float(df[col_juv].sum())\n",
        "    ad_tot = float(df[col_ad].sum())\n",
        "    if ad_tot <= 0:\n",
        "        raise RuntimeError(\"Total ADULTS must be positive to form juveniles/adults ratio.\")\n",
        "\n",
        "    ratio = juv_tot / ad_tot\n",
        "    b3_base = ratio / float(len(breeding_months))\n",
        "\n",
        "    # Monthly base fecundities (length 12)\n",
        "    b3_base_k = np.zeros(12, dtype=float)\n",
        "    for k in breeding_months:\n",
        "        b3_base_k[k-1] = b3_base\n",
        "\n",
        "    return {\n",
        "        \"source_path\": str(path),\n",
        "        \"treatment_label\": str(treatment_label),\n",
        "        \"detected_columns\": {\n",
        "            \"treatment\": col_treat,\n",
        "            \"juveniles\": col_juv,\n",
        "            \"adults\": col_ad,\n",
        "        },\n",
        "        \"juveniles_total\": juv_tot,\n",
        "        \"adults_total\": ad_tot,\n",
        "        \"ratio_juveniles_over_adults\": float(ratio),\n",
        "        \"breeding_months\": list(breeding_months),\n",
        "        \"b3_base_per_breeding_month\": float(b3_base),\n",
        "        \"b3_base_monthly_vector\": b3_base_k.tolist(),\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Model builder (monthly; P=12)\n",
        "# ----------------------------\n",
        "\n",
        "def build_monthly_blocks(\n",
        "    s_scale: float,\n",
        "    sJ_month: np.ndarray,\n",
        "    sA_month: np.ndarray,\n",
        "    b3_base_monthly: np.ndarray,\n",
        "    alpha: float,\n",
        "    theta: float,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Monthly 3-stage model (female + male), with to-from (column-vector) convention:\n",
        "\n",
        "      Female stages: F1 juvenile, F2 yearling, F3 adult\n",
        "      U_f,k:\n",
        "        (2,1) = sJ_k\n",
        "        (3,2) = sA_k  (proxy yearling->adult)\n",
        "        (3,3) = sA_k  (adult retention)\n",
        "\n",
        "      Fecundity vector f_k = [0, b2_k, b3_k]^T (total recruits to next census, both sexes)\n",
        "        b3_k = s_scale * b3_base_k in breeding months\n",
        "        b2_k = theta * b3_k in breeding months, else 0\n",
        "\n",
        "      Male block U_m,k is set equal to U_f,k (sex not disaggregated).\n",
        "    \"\"\"\n",
        "    P = 12\n",
        "    nf = 3\n",
        "    nm = 3\n",
        "\n",
        "    e1f = np.zeros(nf, dtype=float); e1f[0] = 1.0\n",
        "    e1m = np.zeros(nm, dtype=float); e1m[0] = 1.0\n",
        "\n",
        "    U_f_list = []\n",
        "    U_m_list = []\n",
        "    f_list = []\n",
        "    alpha_list = []\n",
        "    A_f_list = []\n",
        "    R_list = []\n",
        "    B_list = []\n",
        "    L_list = []\n",
        "\n",
        "    for k in range(1, P+1):\n",
        "        U_f = np.zeros((nf, nf), dtype=float)\n",
        "        U_f[1, 0] = float(sJ_month[k-1])\n",
        "        U_f[2, 1] = float(sA_month[k-1])\n",
        "        U_f[2, 2] = float(sA_month[k-1])\n",
        "\n",
        "        U_m = U_f.copy()\n",
        "\n",
        "        # Fecundity (both sexes)\n",
        "        b3_k = float(s_scale) * float(b3_base_monthly[k-1])\n",
        "        b2_k = float(theta) * b3_k if b3_k > 0 else 0.0\n",
        "        f_k = np.array([0.0, b2_k, b3_k], dtype=float)\n",
        "\n",
        "        alpha_k = float(alpha)\n",
        "\n",
        "        R_k = alpha_k * np.outer(e1f, f_k)           # female recruits into F1\n",
        "        B_k = (1.0 - alpha_k) * np.outer(e1m, f_k)   # male recruits into M1\n",
        "        A_f_k = U_f + R_k\n",
        "\n",
        "        L_k = np.zeros((nf+nm, nf+nm), dtype=float)\n",
        "        L_k[:nf, :nf] = A_f_k\n",
        "        L_k[nf:, :nf] = B_k\n",
        "        L_k[nf:, nf:] = U_m\n",
        "\n",
        "        U_f_list.append(U_f)\n",
        "        U_m_list.append(U_m)\n",
        "        f_list.append(f_k)\n",
        "        alpha_list.append(alpha_k)\n",
        "        A_f_list.append(A_f_k)\n",
        "        R_list.append(R_k)\n",
        "        B_list.append(B_k)\n",
        "        L_list.append(L_k)\n",
        "\n",
        "    return {\n",
        "        \"P\": P,\n",
        "        \"nf\": nf,\n",
        "        \"nm\": nm,\n",
        "        \"stages_female\": [\"F1 (juvenile)\", \"F2 (yearling)\", \"F3 (adult)\"],\n",
        "        \"stages_male\": [\"M1 (juvenile)\", \"M2 (subadult)\", \"M3 (adult)\"],\n",
        "        \"U_f_list\": U_f_list,\n",
        "        \"U_m_list\": U_m_list,\n",
        "        \"f_list\": f_list,\n",
        "        \"alpha_list\": alpha_list,\n",
        "        \"R_list\": R_list,\n",
        "        \"B_list\": B_list,\n",
        "        \"A_f_list\": A_f_list,\n",
        "        \"L_list\": L_list,\n",
        "        \"b3_monthly\": [float(f[2]) for f in f_list],\n",
        "        \"b2_monthly\": [float(f[1]) for f in f_list],\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Monodromy (period product) and lambda\n",
        "# ----------------------------\n",
        "\n",
        "def monodromy(blocks: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    P = blocks[\"P\"]\n",
        "    nf = blocks[\"nf\"]\n",
        "    nm = blocks[\"nm\"]\n",
        "\n",
        "    M = np.eye(nf + nm, dtype=float)\n",
        "    Mf = np.eye(nf, dtype=float)\n",
        "    Mm = np.eye(nm, dtype=float)\n",
        "\n",
        "    for k in range(P):\n",
        "        Lk = blocks[\"L_list\"][k]\n",
        "        Afk = blocks[\"A_f_list\"][k]\n",
        "        Umk = blocks[\"U_m_list\"][k]\n",
        "\n",
        "        M = Lk @ M\n",
        "        Mf = Afk @ Mf\n",
        "        Mm = Umk @ Mm\n",
        "\n",
        "    rho_M = spectral_radius(M)\n",
        "    rho_Mf = spectral_radius(Mf)\n",
        "    rho_Mm = spectral_radius(Mm)\n",
        "\n",
        "    lam_per_month = rho_M ** (1.0 / P)\n",
        "\n",
        "    return {\n",
        "        \"M\": M,\n",
        "        \"Mf\": Mf,\n",
        "        \"Mm\": Mm,\n",
        "        \"rho_M\": rho_M,\n",
        "        \"rho_Mf\": rho_Mf,\n",
        "        \"rho_Mm\": rho_Mm,\n",
        "        \"lambda_per_month\": lam_per_month,\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Neutrality calibration (solve for s such that rho(M)=1)\n",
        "# ----------------------------\n",
        "\n",
        "def calibrate_scale_s(\n",
        "    sJ_month: np.ndarray,\n",
        "    sA_month: np.ndarray,\n",
        "    b3_base_monthly: np.ndarray,\n",
        "    alpha: float,\n",
        "    theta: float,\n",
        "    target_rho: float = 1.0,\n",
        "    iters: int = 80,\n",
        "    tol: float = 1e-12,\n",
        ") -> float:\n",
        "    def rho_of_s(s: float) -> float:\n",
        "        blk = build_monthly_blocks(s, sJ_month, sA_month, b3_base_monthly, alpha, theta)\n",
        "        return monodromy(blk)[\"rho_M\"]\n",
        "\n",
        "    lo = 0.0\n",
        "    hi = 1.0\n",
        "    # Ensure bracket\n",
        "    while rho_of_s(hi) < target_rho:\n",
        "        hi *= 2.0\n",
        "        if hi > 1e9:\n",
        "            raise RuntimeError(\"Failed to bracket neutrality root; hi exploded.\")\n",
        "\n",
        "    for _ in range(iters):\n",
        "        mid = 0.5 * (lo + hi)\n",
        "        val = rho_of_s(mid)\n",
        "        if abs(val - target_rho) <= tol:\n",
        "            return mid\n",
        "        if val >= target_rho:\n",
        "            hi = mid\n",
        "        else:\n",
        "            lo = mid\n",
        "    return hi\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Periodic next-generation operator K (Eq. Kper in your paper)\n",
        "# ----------------------------\n",
        "\n",
        "def periodic_next_generation_operator(blocks: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Implements:\n",
        "      U_k = U_{f,k} (survival/transition only)\n",
        "      R_k = alpha_k e1 f_k^T  (female recruits only)\n",
        "      U_prod = U_P...U_1\n",
        "\n",
        "      K = sum_k ( R_k * U_{k-1}...U_1 * U_P...U_{k+1} ) * (I - U_prod)^(-1)\n",
        "\n",
        "    Computed via linear solves (no explicit inverse).\n",
        "    Also returns monthly kernel terms T_k used for diagnostics.\n",
        "    \"\"\"\n",
        "    P = blocks[\"P\"]\n",
        "    nf = blocks[\"nf\"]\n",
        "    U_list = blocks[\"U_f_list\"]\n",
        "    R_list = blocks[\"R_list\"]\n",
        "\n",
        "    # U_prod = U_P...U_1\n",
        "    U_prod = np.eye(nf, dtype=float)\n",
        "    for k in range(P):\n",
        "        U_prod = U_list[k] @ U_prod\n",
        "\n",
        "    I = np.eye(nf, dtype=float)\n",
        "\n",
        "    # prev[k] = U_{k-1}...U_1, for k=1..P (prev[1]=I)\n",
        "    prev = [None] * (P + 1)\n",
        "    prev[1] = np.eye(nf, dtype=float)\n",
        "    for k in range(2, P + 1):\n",
        "        prev[k] = U_list[k - 2] @ prev[k - 1]\n",
        "\n",
        "    # next[k] = U_P...U_{k+1}, for k=1..P (next[P]=I)\n",
        "    nxt = [None] * (P + 1)\n",
        "    nxt[P] = np.eye(nf, dtype=float)\n",
        "    for k in range(P - 1, 0, -1):\n",
        "        nxt[k] = nxt[k + 1] @ U_list[k]  # U_{k+1}\n",
        "\n",
        "    # Sum terms\n",
        "    H = np.zeros((nf, nf), dtype=float)\n",
        "    term_list = []\n",
        "    for k in range(1, P + 1):\n",
        "        rot = prev[k] @ nxt[k]  # U_{k-1}...U_1 U_P...U_{k+1}\n",
        "        term = R_list[k - 1] @ rot\n",
        "        term_list.append(term)\n",
        "        H += term\n",
        "\n",
        "    # K = H (I - U_prod)^(-1) via solve:\n",
        "    # K^T solves (I - U_prod)^T K^T = H^T\n",
        "    K = np.linalg.solve((I - U_prod).T, H.T).T\n",
        "\n",
        "    # Monthly kernel terms T_k = term_k (I - U_prod)^(-1) via solve\n",
        "    T_terms = [np.linalg.solve((I - U_prod).T, term.T).T for term in term_list]\n",
        "\n",
        "    R0_per = spectral_radius(K)\n",
        "\n",
        "    # Norm-based diagnostics c_k ∝ ||T_k||_1\n",
        "    norms = np.array([induced_matrix_1norm(T) for T in T_terms], dtype=float)\n",
        "    denom = float(np.sum(norms)) if float(np.sum(norms)) > 0 else 1.0\n",
        "    c_k = (norms / denom).tolist()\n",
        "\n",
        "    return {\n",
        "        \"U_prod\": U_prod,\n",
        "        \"K\": K,\n",
        "        \"R0_per\": R0_per,\n",
        "        \"T_terms\": T_terms,\n",
        "        \"c_k\": c_k,\n",
        "        \"norms\": norms.tolist(),\n",
        "    }\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Projections (30 months) and newborn output\n",
        "# ----------------------------\n",
        "\n",
        "def project_months(blocks: Dict[str, Any], T: int = 30, x0: Optional[np.ndarray] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Iterate x(t+1)=L_k x(t), cycling k mod 12.\n",
        "    Report newborn output N(t+1)=f_k^T F(t) each month (caregiver baseline).\n",
        "    \"\"\"\n",
        "    P = blocks[\"P\"]\n",
        "    nf = blocks[\"nf\"]\n",
        "    nm = blocks[\"nm\"]\n",
        "    L_list = blocks[\"L_list\"]\n",
        "    f_list = blocks[\"f_list\"]\n",
        "\n",
        "    if x0 is None:\n",
        "        # Use Perron start from full monodromy to minimize transients\n",
        "        M = monodromy(blocks)[\"M\"]\n",
        "        v = perron_right(M)\n",
        "        # Scale to arbitrary total abundance (paper uses arbitrary units)\n",
        "        total = 1000.0\n",
        "        v = v / np.sum(v) * total\n",
        "        x0 = v\n",
        "\n",
        "    x = x0.copy().astype(float)\n",
        "    X = np.zeros((T + 1, nf + nm), dtype=float)\n",
        "    N = np.zeros(T, dtype=float)\n",
        "\n",
        "    X[0, :] = x\n",
        "    for t in range(T):\n",
        "        k = (t % P)  # 0..11\n",
        "        F = x[:nf]\n",
        "        f_k = f_list[k]\n",
        "        N[t] = float(np.dot(f_k, F))  # total recruits to next census (both sexes)\n",
        "        x = L_list[k] @ x\n",
        "        X[t + 1, :] = x\n",
        "\n",
        "    return {\"X\": X, \"N\": N, \"x0\": x0}\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Periodic stable stage distribution table (female only)\n",
        "# ----------------------------\n",
        "\n",
        "def periodic_stable_female_distribution(blocks: Dict[str, Any]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute periodic stable stage distribution sequence for females:\n",
        "      - Get Perron right eigenvector w1 of female monodromy Mf\n",
        "      - Propagate within-year w_{k+1} = A_f,k w_k\n",
        "      - Normalize each month to sum 1\n",
        "    Returns array shape (12, nf): rows = months 1..12\n",
        "    \"\"\"\n",
        "    P = blocks[\"P\"]\n",
        "    nf = blocks[\"nf\"]\n",
        "    Af_list = blocks[\"A_f_list\"]\n",
        "    Mf = monodromy(blocks)[\"Mf\"]\n",
        "\n",
        "    w1 = perron_right(Mf)\n",
        "    if np.sum(w1) <= 0:\n",
        "        w1 = np.ones(nf, dtype=float)\n",
        "    w1 = np.abs(w1)\n",
        "    # propagate\n",
        "    W = np.zeros((P, nf), dtype=float)\n",
        "    w = w1.copy()\n",
        "    for k in range(P):\n",
        "        w = np.abs(w)\n",
        "        s = float(np.sum(w))\n",
        "        W[k, :] = w / (s if s > 0 else 1.0)\n",
        "        w = Af_list[k] @ w\n",
        "    return W\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Invasion curve (Beverton–Holt)\n",
        "# ----------------------------\n",
        "\n",
        "def beverton_holt_psi(eta: np.ndarray, h: float = 1.0) -> np.ndarray:\n",
        "    return eta / (h + eta)\n",
        "\n",
        "def invasion_curve(R0_per: float, eta_max: float, n: int, h: float = 1.0) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    eta = np.linspace(0.0, float(eta_max), int(n))\n",
        "    psi = beverton_holt_psi(eta, h=h)\n",
        "    R = psi * float(R0_per)\n",
        "    return eta, R\n",
        "\n",
        "def invasion_fingerprint_table(R0_values: Dict[str, float], etas: List[float], h: float = 1.0) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for label, R0v in R0_values.items():\n",
        "        row = {\"Scenario\": label}\n",
        "        for e in etas:\n",
        "            row[f\"R(eta={e:g})\"] = float(beverton_holt_psi(np.array([e]), h=h)[0] * R0v)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Writers\n",
        "# ----------------------------\n",
        "\n",
        "def write_yaml_or_json(obj: Dict[str, Any], yaml_path: Path, json_path: Path) -> None:\n",
        "    ensure_dir(yaml_path.parent)\n",
        "    ensure_dir(json_path.parent)\n",
        "\n",
        "    # JSON always\n",
        "    with json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, indent=2, sort_keys=True)\n",
        "\n",
        "    yaml = _try_import_yaml()\n",
        "    if yaml is not None:\n",
        "        with yaml_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "            yaml.safe_dump(obj, f, sort_keys=False)\n",
        "\n",
        "def write_metrics_macros(pdS: float, pdR0: float, pdLambda: float, pdRhoMm: float, out_path: Path) -> None:\n",
        "    ensure_dir(out_path.parent)\n",
        "    lines = []\n",
        "    lines.append(\"% Auto-generated prairie-dog macros\")\n",
        "    lines.append(rf\"\\def\\pdS{{{pdS:.6f}}}\")\n",
        "    lines.append(rf\"\\def\\pdRzeroPer{{{pdR0:.6f}}}\")\n",
        "    lines.append(rf\"\\def\\pdLambda{{{pdLambda:.6f}}}\")\n",
        "    lines.append(rf\"\\def\\pdRhoMm{{{pdRhoMm:.6f}}}\")\n",
        "    lines.append(\"\")\n",
        "    out_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "def write_pd_periodic_ssd_tex(W: np.ndarray, out_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Writes pd_periodic_ssd.tex compatible with your supplement \\IfFileExists{pd_periodic_ssd.tex}{...}.\n",
        "    \"\"\"\n",
        "    ensure_dir(out_path.parent)\n",
        "    lines = []\n",
        "    lines.append(r\"\\begin{tabular}{@{}lccc@{}}\")\n",
        "    lines.append(r\"\\toprule\")\n",
        "    lines.append(r\"Month & $\\hat F_{1,k}$ & $\\hat F_{2,k}$ & $\\hat F_{3,k}$\\\\\")\n",
        "    lines.append(r\"\\midrule\")\n",
        "    for k in range(12):\n",
        "        lines.append(f\"{k+1} & {W[k,0]:.6f} & {W[k,1]:.6f} & {W[k,2]:.6f}\\\\\\\\\")\n",
        "    lines.append(r\"\\bottomrule\")\n",
        "    lines.append(r\"\\end{tabular}\")\n",
        "    lines.append(\"\")\n",
        "    out_path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Plotting\n",
        "# ----------------------------\n",
        "\n",
        "def plot_newborns(N: np.ndarray, out_path: Path) -> None:\n",
        "    ensure_dir(out_path.parent)\n",
        "    t = np.arange(1, len(N) + 1)\n",
        "    ma = moving_average(N, window=3)\n",
        "    plt.figure()\n",
        "    plt.plot(t, N, label=\"Newborn/recruit output N(t+1)\")\n",
        "    plt.plot(t, ma, linestyle=\"--\", label=\"3-month moving avg\")\n",
        "    plt.xlabel(\"Month (t)\")\n",
        "    plt.ylabel(\"Recruits to next census (both sexes)\")\n",
        "    plt.title(\"Prairie dog: monthly recruit output (caregiver baseline)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def plot_projection(X: np.ndarray, out_path: Path) -> None:\n",
        "    ensure_dir(out_path.parent)\n",
        "    T = X.shape[0] - 1\n",
        "    t = np.arange(0, T + 1)\n",
        "\n",
        "    # Stages: female 0..2, male 3..5\n",
        "    plt.figure()\n",
        "    plt.plot(t, X[:, 0], label=\"F1 (juvenile)\")\n",
        "    plt.plot(t, X[:, 1], label=\"F2 (yearling)\")\n",
        "    plt.plot(t, X[:, 2], label=\"F3 (adult)\")\n",
        "\n",
        "    plt.plot(t, X[:, 3], linestyle=\"--\", label=\"M1 (juvenile)\")\n",
        "    plt.plot(t, X[:, 4], linestyle=\"--\", label=\"M2 (subadult)\")\n",
        "    plt.plot(t, X[:, 5], linestyle=\"--\", label=\"M3 (adult)\")\n",
        "\n",
        "    plt.xlabel(\"Month (t)\")\n",
        "    plt.ylabel(\"Abundance (arbitrary units)\")\n",
        "    plt.title(\"Prairie dog projections (caregiver baseline; P=12)\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def plot_R0_contrib(c_k: List[float], out_path: Path) -> None:\n",
        "    ensure_dir(out_path.parent)\n",
        "    months = np.arange(1, 13)\n",
        "    plt.figure()\n",
        "    plt.bar(months, c_k)\n",
        "    plt.xlabel(\"Month k (1..12)\")\n",
        "    plt.ylabel(r\"Diagnostic weight $c_k$\")\n",
        "    plt.title(r\"Prairie dog: norm-based monthly diagnostics for $R_{0,\\mathrm{per}}$\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def plot_invasion_curve(eta: np.ndarray, R: np.ndarray, out_path: Path) -> None:\n",
        "    ensure_dir(out_path.parent)\n",
        "    plt.figure()\n",
        "    plt.plot(eta, R)\n",
        "    plt.axhline(1.0, linestyle=\"--\")\n",
        "    plt.xlabel(r\"Stocking intensity $\\eta$\")\n",
        "    plt.ylabel(r\"$R_{F\\mid M^\\star}(\\eta)$\")\n",
        "    plt.title(\"Prairie dog: female invasion curve under Beverton–Holt male availability\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Main\n",
        "# ----------------------------\n",
        "\n",
        "def main(cfg: PrairieDogConfig) -> None:\n",
        "    # Output dirs (match your paper's conventions)\n",
        "    out_root = Path(\"out\")\n",
        "    out_params = out_root / \"params\"\n",
        "    out_figs = out_root / \"figs\"\n",
        "    out_summary = out_root / \"summary\"\n",
        "    out_tables = out_root / \"tables\"\n",
        "    out_tex = out_root / \"tex\"\n",
        "\n",
        "    ensure_dir(out_params)\n",
        "    ensure_dir(out_figs)\n",
        "    ensure_dir(out_summary)\n",
        "    ensure_dir(out_tables)\n",
        "    ensure_dir(out_tex)\n",
        "\n",
        "    # Resolve input files\n",
        "    if cfg.survival_csv is not None and cfg.reproduction_csv is not None:\n",
        "        survival_path = Path(cfg.survival_csv)\n",
        "        reproduction_path = Path(cfg.reproduction_csv)\n",
        "    else:\n",
        "        # Auto-detect from CSVs in working dir\n",
        "        csvs = sorted(Path(\".\").glob(\"*.csv\"))\n",
        "        if len(csvs) < 2:\n",
        "            raise RuntimeError(\n",
        "                \"Need survival and reproduction CSV files in the working directory. \"\n",
        "                \"Upload them to Colab (e.g., /content) or set CONFIG.survival_csv and CONFIG.reproduction_csv.\"\n",
        "            )\n",
        "        survival_path, reproduction_path = detect_survival_vs_reproduction_csv(csvs)\n",
        "\n",
        "    # Ingest data\n",
        "    surv_info = ingest_survival(\n",
        "        survival_path,\n",
        "        treatment_label=cfg.treatment_label,\n",
        "        interval_m=cfg.interval_months_when_month_missing,\n",
        "    )\n",
        "    repro_info = ingest_reproduction(\n",
        "        reproduction_path,\n",
        "        treatment_label=cfg.treatment_label,\n",
        "        breeding_months=cfg.breeding_months,\n",
        "    )\n",
        "\n",
        "    # Extract monthly survivals (length 12)\n",
        "    sJ_month = np.array(surv_info[\"sJ_month\"], dtype=float)\n",
        "    sA_month = np.array(surv_info[\"sA_month\"], dtype=float)\n",
        "    b3_base_monthly = np.array(repro_info[\"b3_base_monthly_vector\"], dtype=float)\n",
        "\n",
        "    # Calibrate s so that rho(M)=1 (annual neutrality)\n",
        "    s_star = calibrate_scale_s(\n",
        "        sJ_month=sJ_month,\n",
        "        sA_month=sA_month,\n",
        "        b3_base_monthly=b3_base_monthly,\n",
        "        alpha=cfg.alpha,\n",
        "        theta=cfg.theta_yearling_fraction,\n",
        "        target_rho=1.0,\n",
        "        iters=cfg.bisect_iters,\n",
        "        tol=cfg.bisect_tol,\n",
        "    )\n",
        "\n",
        "    # Build final blocks with calibrated s\n",
        "    blocks = build_monthly_blocks(\n",
        "        s_scale=s_star,\n",
        "        sJ_month=sJ_month,\n",
        "        sA_month=sA_month,\n",
        "        b3_base_monthly=b3_base_monthly,\n",
        "        alpha=cfg.alpha,\n",
        "        theta=cfg.theta_yearling_fraction,\n",
        "    )\n",
        "\n",
        "    # Monodromy metrics\n",
        "    mono = monodromy(blocks)\n",
        "\n",
        "    # Periodic next-generation operator + diagnostics\n",
        "    ng = periodic_next_generation_operator(blocks)\n",
        "\n",
        "    # Projections\n",
        "    proj = project_months(blocks, T=cfg.projection_months, x0=None)\n",
        "\n",
        "    # Periodic stable female distribution table\n",
        "    W = periodic_stable_female_distribution(blocks)\n",
        "\n",
        "    # Invasion curve (paper illustration uses Beverton–Holt with h_m=1)\n",
        "    eta, R_inv = invasion_curve(\n",
        "        R0_per=float(ng[\"R0_per\"]),\n",
        "        eta_max=cfg.invasion_eta_max,\n",
        "        n=cfg.invasion_eta_n,\n",
        "        h=cfg.invasion_hm,\n",
        "    )\n",
        "\n",
        "    # Invasion fingerprint table (as in paper)\n",
        "    # Baseline uses R0_per from the calibrated run (should be ~1).\n",
        "    R0_values = {\n",
        "        \"Calibrated baseline (R0_per=1)\": float(ng[\"R0_per\"]),\n",
        "        \"Supercritical illustration (R0_per=1.250)\": 1.250,\n",
        "        \"Treated fecundity (R0_per=0.672)\": 0.672,\n",
        "    }\n",
        "    fingerprint = invasion_fingerprint_table(R0_values, etas=[0, 1, 5, 10], h=cfg.invasion_hm)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Write outputs (params/audit/schema/summary/macros)\n",
        "    # ----------------------------\n",
        "\n",
        "    # Audit aggregation report (CSV)\n",
        "    # (Matches your paper narrative: pooled survivals + converted per-month survivals + reproduction ratio)\n",
        "    pooled = surv_info.get(\"pooled\", None)\n",
        "    audit_rows = []\n",
        "    if pooled is not None:\n",
        "        audit_rows.append({\n",
        "            \"treatment\": cfg.treatment_label,\n",
        "            \"age_class\": \"J\",\n",
        "            \"n\": pooled[\"nJ\"],\n",
        "            \"s_pooled\": pooled[\"sJ_pooled\"],\n",
        "            \"m_interval\": cfg.interval_months_when_month_missing,\n",
        "            \"s_month\": pooled[\"sJ_month_converted\"],\n",
        "        })\n",
        "        audit_rows.append({\n",
        "            \"treatment\": cfg.treatment_label,\n",
        "            \"age_class\": \"A\",\n",
        "            \"n\": pooled[\"nA\"],\n",
        "            \"s_pooled\": pooled[\"sA_pooled\"],\n",
        "            \"m_interval\": cfg.interval_months_when_month_missing,\n",
        "            \"s_month\": pooled[\"sA_month_converted\"],\n",
        "        })\n",
        "    else:\n",
        "        # Month field present: store monthwise counts (compact)\n",
        "        audit_rows.append({\n",
        "            \"treatment\": cfg.treatment_label,\n",
        "            \"note\": \"Month field present; see surv_info in prairie_dog_input_full.yaml for monthwise means/counts.\"\n",
        "        })\n",
        "\n",
        "    # Reproduction audit\n",
        "    audit_rows.append({\n",
        "        \"treatment\": cfg.treatment_label,\n",
        "        \"juveniles_total\": repro_info[\"juveniles_total\"],\n",
        "        \"adults_total\": repro_info[\"adults_total\"],\n",
        "        \"ratio_juveniles_over_adults\": repro_info[\"ratio_juveniles_over_adults\"],\n",
        "        \"breeding_months\": \",\".join(str(m) for m in cfg.breeding_months),\n",
        "        \"b3_base_per_breeding_month\": repro_info[\"b3_base_per_breeding_month\"],\n",
        "        \"s_star_neutrality_scale\": float(s_star),\n",
        "    })\n",
        "\n",
        "    audit_df = pd.DataFrame(audit_rows)\n",
        "    audit_csv_path = out_params / \"pd_usgs_aggregation_report.csv\"\n",
        "    audit_df.to_csv(audit_csv_path, index=False)\n",
        "\n",
        "    # Schema/provenance\n",
        "    schema = {\n",
        "        \"system\": \"prairie_dog_USGS\",\n",
        "        \"period_P\": 12,\n",
        "        \"census\": \"monthly pre-breeding\",\n",
        "        \"state_convention\": \"column-vector; to-from indexing; newborns not a state; recruits enter F1/M1 at next census\",\n",
        "        \"treatment_label\": cfg.treatment_label,\n",
        "        \"breeding_months\": list(cfg.breeding_months),\n",
        "        \"interval_m_when_month_missing\": cfg.interval_months_when_month_missing,\n",
        "        \"sex_ratio_alpha\": cfg.alpha,\n",
        "        \"theta_yearling_fraction\": cfg.theta_yearling_fraction,\n",
        "        \"detected_columns\": {\n",
        "            \"survival_csv\": surv_info[\"detected_columns\"],\n",
        "            \"reproduction_csv\": repro_info[\"detected_columns\"],\n",
        "        },\n",
        "        \"input_files\": {\n",
        "            \"survival_csv\": str(survival_path),\n",
        "            \"reproduction_csv\": str(reproduction_path),\n",
        "        },\n",
        "    }\n",
        "    write_yaml_or_json(\n",
        "        schema,\n",
        "        yaml_path=out_params / \"pd_schema.yaml\",\n",
        "        json_path=out_params / \"pd_schema.json\",\n",
        "    )\n",
        "\n",
        "    # Full input bundle (machine-readable)\n",
        "    input_full = {\n",
        "        \"stages\": {\n",
        "            \"female\": blocks[\"stages_female\"],\n",
        "            \"male\": blocks[\"stages_male\"],\n",
        "        },\n",
        "        \"alpha\": cfg.alpha,\n",
        "        \"breeding_months\": list(cfg.breeding_months),\n",
        "        \"theta_yearling_fraction\": cfg.theta_yearling_fraction,\n",
        "        \"survival_inputs\": {\n",
        "            \"sJ_month\": sJ_month.tolist(),\n",
        "            \"sA_month\": sA_month.tolist(),\n",
        "            \"survival_ingestion\": surv_info,\n",
        "        },\n",
        "        \"reproduction_inputs\": {\n",
        "            \"b3_base_monthly_vector\": b3_base_monthly.tolist(),\n",
        "            \"reproduction_ingestion\": repro_info,\n",
        "        },\n",
        "        \"calibration\": {\n",
        "            \"s_star\": float(s_star),\n",
        "            \"target_rho_M\": 1.0,\n",
        "        },\n",
        "        \"monthly_fecundities_used\": {\n",
        "            \"b2_monthly\": blocks[\"b2_monthly\"],\n",
        "            \"b3_monthly\": blocks[\"b3_monthly\"],\n",
        "        },\n",
        "        # Matrices (small; included for audit)\n",
        "        \"U_f_list\": [U.tolist() for U in blocks[\"U_f_list\"]],\n",
        "        \"U_m_list\": [U.tolist() for U in blocks[\"U_m_list\"]],\n",
        "        \"f_list\": [f.tolist() for f in blocks[\"f_list\"]],\n",
        "        \"A_f_list\": [A.tolist() for A in blocks[\"A_f_list\"]],\n",
        "    }\n",
        "    write_yaml_or_json(\n",
        "        input_full,\n",
        "        yaml_path=out_params / \"prairie_dog_input_full.yaml\",\n",
        "        json_path=out_params / \"prairie_dog_input_full.json\",\n",
        "    )\n",
        "\n",
        "    # Summary JSON (results)\n",
        "    results_summary = {\n",
        "        \"system\": \"prairie_dog_USGS\",\n",
        "        \"period_P\": 12,\n",
        "        \"metrics\": {\n",
        "            \"s_star\": float(s_star),\n",
        "            \"R0_per\": float(ng[\"R0_per\"]),\n",
        "            \"rho_M\": float(mono[\"rho_M\"]),                 # = lambda^12\n",
        "            \"lambda_per_month\": float(mono[\"lambda_per_month\"]),\n",
        "            \"rho_Mf\": float(mono[\"rho_Mf\"]),               # female block\n",
        "            \"rho_Mm\": float(mono[\"rho_Mm\"]),               # male survival product block\n",
        "            \"rho_Uf_period\": float(spectral_radius(ng[\"U_prod\"])),\n",
        "        },\n",
        "        \"diagnostics\": {\n",
        "            \"c_k\": ng[\"c_k\"],   # norm-based monthwise diagnostics\n",
        "        },\n",
        "        \"inputs\": {\n",
        "            \"treatment_label\": cfg.treatment_label,\n",
        "            \"breeding_months\": list(cfg.breeding_months),\n",
        "            \"interval_m_when_month_missing\": cfg.interval_months_when_month_missing,\n",
        "            \"alpha\": cfg.alpha,\n",
        "            \"theta\": cfg.theta_yearling_fraction,\n",
        "        },\n",
        "    }\n",
        "    with (out_summary / \"RESULTS_SUMMARY_prairie_dog.json\").open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results_summary, f, indent=2, sort_keys=True)\n",
        "\n",
        "    # LaTeX macros (for your manuscript)\n",
        "    # pdS, pdRzeroPer, pdLambda, pdRhoMm\n",
        "    macros_path = out_root / \"metrics_macros.tex\"\n",
        "    write_metrics_macros(\n",
        "        pdS=float(s_star),\n",
        "        pdR0=float(ng[\"R0_per\"]),\n",
        "        pdLambda=float(mono[\"lambda_per_month\"]),\n",
        "        pdRhoMm=float(mono[\"rho_Mm\"]),\n",
        "        out_path=macros_path,\n",
        "    )\n",
        "    # Also write a copy at repo root if desired\n",
        "    write_metrics_macros(\n",
        "        pdS=float(s_star),\n",
        "        pdR0=float(ng[\"R0_per\"]),\n",
        "        pdLambda=float(mono[\"lambda_per_month\"]),\n",
        "        pdRhoMm=float(mono[\"rho_Mm\"]),\n",
        "        out_path=Path(\"metrics_macros.tex\"),\n",
        "    )\n",
        "\n",
        "    # Periodic SSD table (supplement hook)\n",
        "    write_pd_periodic_ssd_tex(W, Path(\"pd_periodic_ssd.tex\"))\n",
        "    write_pd_periodic_ssd_tex(W, out_tables / \"pd_periodic_ssd.tex\")\n",
        "\n",
        "    # Invasion fingerprint outputs\n",
        "    fingerprint_csv = out_tables / \"pd_invasion_fingerprint.csv\"\n",
        "    fingerprint.to_csv(fingerprint_csv, index=False)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Figures\n",
        "    # ----------------------------\n",
        "    plot_newborns(proj[\"N\"], out_figs / \"pd_newborns.png\")\n",
        "    plot_projection(proj[\"X\"], out_figs / \"pd_projection.png\")\n",
        "    plot_R0_contrib(ng[\"c_k\"], out_figs / \"pd_R0_contrib.png\")\n",
        "    plot_invasion_curve(eta, R_inv, out_figs / \"pd_invasion_curve.png\")\n",
        "\n",
        "    # Also copy figures to current directory for convenience (like your polar-bear runs)\n",
        "    for fn in [\"pd_newborns.png\", \"pd_projection.png\", \"pd_R0_contrib.png\", \"pd_invasion_curve.png\"]:\n",
        "        src = out_figs / fn\n",
        "        if src.exists():\n",
        "            Path(fn).write_bytes(src.read_bytes())\n",
        "\n",
        "    # ----------------------------\n",
        "    # Console report (should match paper numbers)\n",
        "    # ----------------------------\n",
        "    print(\"=== Prairie dog (USGS; P=12) caregiver baseline ===\")\n",
        "    print(f\"Input files:\")\n",
        "    print(f\"  survival:      {survival_path}\")\n",
        "    print(f\"  reproduction:  {reproduction_path}\")\n",
        "    print(\"\")\n",
        "    if surv_info.get(\"pooled\", None) is not None:\n",
        "        print(\"Survival ingestion (month missing => pooled -> per-month conversion):\")\n",
        "        print(f\"  pooled s_J = {surv_info['pooled']['sJ_pooled']:.6f}  (n={surv_info['pooled']['nJ']})\")\n",
        "        print(f\"  pooled s_A = {surv_info['pooled']['sA_pooled']:.6f}  (n={surv_info['pooled']['nA']})\")\n",
        "        print(f\"  per-month s_J = {surv_info['pooled']['sJ_month_converted']:.6f}\")\n",
        "        print(f\"  per-month s_A = {surv_info['pooled']['sA_month_converted']:.6f}\")\n",
        "        print(\"\")\n",
        "    print(\"Reproduction ingestion:\")\n",
        "    print(f\"  juveniles_total = {repro_info['juveniles_total']:.6f}\")\n",
        "    print(f\"  adults_total    = {repro_info['adults_total']:.6f}\")\n",
        "    print(f\"  ratio J/A       = {repro_info['ratio_juveniles_over_adults']:.6f}\")\n",
        "    print(f\"  b3_base (Apr-Jun each) = {repro_info['b3_base_per_breeding_month']:.6f}\")\n",
        "    print(\"\")\n",
        "    print(\"Calibrated neutrality:\")\n",
        "    print(f\"  s* = {s_star:.6f}\")\n",
        "    print(f\"  rho(M)=lambda^12 = {mono['rho_M']:.6f}\")\n",
        "    print(f\"  lambda (per month) = {mono['lambda_per_month']:.6f}\")\n",
        "    print(f\"  rho(M_f) = {mono['rho_Mf']:.6f}\")\n",
        "    print(f\"  rho(M_m) = {mono['rho_Mm']:.6f}\")\n",
        "    print(\"\")\n",
        "    print(\"Periodic next-generation operator:\")\n",
        "    print(f\"  R0_per = rho(K) = {ng['R0_per']:.6f}\")\n",
        "    print(\"\")\n",
        "    print(\"Wrote key outputs:\")\n",
        "    print(f\"  {out_params / 'prairie_dog_input_full.yaml'} (and .json)\")\n",
        "    print(f\"  {audit_csv_path}\")\n",
        "    print(f\"  {out_params / 'pd_schema.yaml'} (and .json)\")\n",
        "    print(f\"  {out_summary / 'RESULTS_SUMMARY_prairie_dog.json'}\")\n",
        "    print(f\"  {macros_path} and ./metrics_macros.tex\")\n",
        "    print(f\"  ./pd_periodic_ssd.tex\")\n",
        "    print(f\"  Figures in {out_figs} (also copied to ./)\")\n",
        "    print(f\"  Fingerprint table: {fingerprint_csv}\")\n",
        "\n",
        "\n",
        "# Run (Colab)\n",
        "if __name__ == \"__main__\":\n",
        "    main(CONFIG)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jVOkvLA-nV9P",
        "outputId": "f3f76701-0bcd-440f-dc44-32dd7b2b7ddd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:748: SyntaxWarning: invalid escape sequence '\\I'\n",
            "<>:748: SyntaxWarning: invalid escape sequence '\\I'\n",
            "/tmp/ipython-input-1091028.py:748: SyntaxWarning: invalid escape sequence '\\I'\n",
            "  Writes pd_periodic_ssd.tex compatible with your supplement \\IfFileExists{pd_periodic_ssd.tex}{...}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Prairie dog (USGS; P=12) caregiver baseline ===\n",
            "Input files:\n",
            "  survival:      Fipronil 2018 Monthly Survival.csv\n",
            "  reproduction:  Fipronil 2020 Reproduction.csv\n",
            "\n",
            "Survival ingestion (month missing => pooled -> per-month conversion):\n",
            "  pooled s_J = 0.582278  (n=79)\n",
            "  pooled s_A = 0.471074  (n=121)\n",
            "  per-month s_J = 0.955933\n",
            "  per-month s_A = 0.939199\n",
            "\n",
            "Reproduction ingestion:\n",
            "  juveniles_total = 1.000000\n",
            "  adults_total    = 24.000000\n",
            "  ratio J/A       = 0.041667\n",
            "  b3_base (Apr-Jun each) = 0.013889\n",
            "\n",
            "Calibrated neutrality:\n",
            "  s* = 49.731746\n",
            "  rho(M)=lambda^12 = 1.000000\n",
            "  lambda (per month) = 1.000000\n",
            "  rho(M_f) = 1.000000\n",
            "  rho(M_m) = 0.471074\n",
            "\n",
            "Periodic next-generation operator:\n",
            "  R0_per = rho(K) = 1.000000\n",
            "\n",
            "Wrote key outputs:\n",
            "  out/params/prairie_dog_input_full.yaml (and .json)\n",
            "  out/params/pd_usgs_aggregation_report.csv\n",
            "  out/params/pd_schema.yaml (and .json)\n",
            "  out/summary/RESULTS_SUMMARY_prairie_dog.json\n",
            "  out/metrics_macros.tex and ./metrics_macros.tex\n",
            "  ./pd_periodic_ssd.tex\n",
            "  Figures in out/figs (also copied to ./)\n",
            "  Fingerprint table: out/tables/pd_invasion_fingerprint.csv\n"
          ]
        }
      ]
    }
  ]
}